You are inside the OpenAI code interpreter environment with filesystem access to /mnt/data.

Mission summary: Implement a single command that (a) runs the QA gate against DRAFT_REPORT_v0.md + pilot artifacts, then (b) emits QA_REPORT.json and QA_REPORT.md with per-check status, error messages, and remediation pointers.
Project: generated_script_1766624721466 (json script)

Target file details:
- Path: qa/qa_checks.py
- Purpose: Implements all QA checks, orchestration, and report generation with per-check status, error messages, and remediation pointers.
- Category: source

Other planned files (for context only):
- scripts/qa_run.sh: Single entrypoint command that runs the QA gate against DRAFT_REPORT_v0.md plus pilot artifacts and emits QA_REPORT.json and QA_REPORT.md.
- qa/schema_qa_report.json: JSON Schema defining the structure of QA_REPORT.json including run metadata and per-check results.
- qa/remediation_catalog.json: Central catalog mapping check IDs to remediation pointers used in both JSON and Markdown reports.
- qa/README.md: Documentation describing how to run the QA command, what artifacts are validated, and how to interpret QA_REPORT.json and QA_REPORT.md.

Reference insights:
- [INTROSPECTION] 2025-12-25T00-21-55-842Z_qa_checks_py_stage1_attempt1_prompt.txt from code-creation agent agent_1766622114110_412seks: You a
- [INTROSPECTION] 2025-12-25T00-21-55-842Z_scripts_qa_run_sh_stage1_attempt1_prompt.txt from code-creation agent agent_1766622114110_412seks: 
- [AGENT INSIGHT: agent_1766614627655_4lrkb6s] Implication 1: Measurement design becomes a hidden equity lever (and risk). If “genius” persist
- [CONSOLIDATED] Establishing clear, machine-validated structure (schemas) and lightweight automation (scaffolding, indexing, path canonicaliz
- [INTROSPECTION] 2025-12-24T23-35-50-952Z_scripts_validate_outputs_py_stage1_attempt1_prompt.txt from code-creation agent agent_1766619349563

Stage details:
- Stage: Stage 1
- Mode: create
- Goal: Implements all QA checks, orchestration, and report generation with per-check status, error messages, and remediation pointers.
- Line budget for this stage: <= 150 new/changed lines.

Implementation tasks (execute using Python in this environment):
1. from pathlib import Path
2. import json
3. target_path = Path('/mnt/data').joinpath('qa/qa_checks.py')
4. target_path.parent.mkdir(parents=True, exist_ok=True)
5. Build the entire stage deliverable (<= 150 lines) as a list named chunks where each item is a multiline string representing a contiguous block of code without leading or trailing blank lines.
6. final_text = '\n'.join(block.strip('\n') for block in chunks).strip() + '\n'
7. target_path.write_text(final_text, encoding='utf-8')
8. print('FILE_WRITTEN:qa/qa_checks.py')
9. print('DIR_STATE:' + json.dumps(sorted(str(p.relative_to(Path("/mnt/data"))) for p in target_path.parent.glob('*') if p.is_file())))

Constraints:
- Ensure the new file fully satisfies the stage goal with no placeholders or TODO markers.
- Keep the newly written code within the stated line/character budget.
- Keep console output short (only FILE_WRITTEN / DIR_STATE plus essential status).
- Do not touch files outside qa/qa_checks.py.
- After writing the file, provide a one-sentence summary. Do not list the file contents in the final message.
