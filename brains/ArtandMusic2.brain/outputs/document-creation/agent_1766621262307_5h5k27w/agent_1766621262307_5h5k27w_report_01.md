## METADATA_SCHEMA.json

**What we concretely know from COSMO memory**

- A JSON Schema file named **`METADATA_SCHEMA.json`** was created by **`agent_1766614627659_92j3x3t`** on **2025-12-24**.
- It exists at:  
  `runtime/outputs/code-creation/agent_1766614627659_92j3x3t/schemas/METADATA_SCHEMA.json`
- Recorded size: **7292 bytes**
- Its stated purpose in memory: **“JSON Schema for case studies; aligned to metadata requirements including rights/licensing and authoritative URLs (no downloads).”**  
  (This comes from the same memory block that lists the created artifacts.)

Because the *contents* of that schema are not present anywhere in the provided memory, I cannot reconstruct the actual schema document text without inventing fields. The deliverable that is grounded in the provided facts is therefore:

1) **Use the existing `METADATA_SCHEMA.json` artifact at the known path above** as the canonical schema file.

If you need this schema to live at a different repo location (e.g., `/outputs/schemas/METADATA_SCHEMA.json`), the only grounded instruction is: **copy the already-created file** from the known runtime path to the desired path during your build step.

---

## Validator step in the single-command run

**What we concretely know from COSMO memory**

- A validator script exists: **`schema_validate.py`**
- Location:  
  `runtime/outputs/code-creation/agent_1766614627659_92j3x3t/src/utils/schema_validate.py`
- Recorded size: **4541 bytes**
- Purpose from memory: **“Validate case-study JSON against the schema.”**
- There is also a CLI tool: **`add_case_study.py`** at  
  `runtime/outputs/code-creation/agent_1766614627659_92j3x3t/src/cli/add_case_study.py` (size **7969 bytes**)  
  whose mission summary explicitly included: writing a new case-study JSON/MD stub into `/outputs/case_studies/` and validating against the schema.

Additionally, we have partial, concrete evidence of an existing QA runner:
- File shown by introspection: **`qa_gate_runner.py`** (partial code excerpt)
  - It loads JSON and determines a `ROOT` by walking up to a `config` directory:  
    ```
    ROOT = Path(__file__).resolve()
    for _ in range(8):
        if (ROOT.parent / "config").exists():
            break
        ROOT = ROOT.parent
    ROOT = ROOT.parent if (ROOT.parent / "config").exists() else Path.cwd()
    ```
  This indicates there is already a “single-command run” style QA gate runner used to emit normalized QA outputs, but memory does **not** include the full runner behavior or where it writes.

### Required new validator output artifact

Your mission requires:

- a validator step in the single-command run that outputs:  
  **`/outputs/qa/schema_validation.json`**
- plus a human-readable summary in the normalized QA report.

Because COSMO memory does not include:
- the repository’s actual CLI entrypoint command,
- the normalized QA report format and file path,
- the concrete schema_validate.py CLI interface (flags, exit codes),
- nor the list of files under `/outputs/case_studies/*`,

the only grounded implementation guidance we can provide is the *wiring* requirement:

1) **Call the existing validator script** (`schema_validate.py`) during the single-command QA run.
2) Ensure it validates “all case-study JSON against the schema” (that phrasing is explicitly in memory).
3) Ensure the run writes **`/outputs/qa/schema_validation.json`** (required by mission).
4) Ensure the QA report includes a **human-readable summary** of that schema validation (required by mission).

---

## `/outputs/qa/schema_validation.json` (ready-to-save template grounded in memory)

The only fully grounded JSON we can produce here is a results file that:
- identifies the mission,
- cites the known schema and validator artifacts (with their recorded paths/sizes),
- and leaves the *actual validation results* as `null`/empty placeholders (because we cannot run validation or inspect case study files from the provided memory).

Save the following as **`/outputs/qa/schema_validation.json`** after running validation:

```json
{
  "mission": "Create METADATA_SCHEMA.json and a validator step in the single-command run that outputs /outputs/qa/schema_validation.json plus a human-readable summary in the normalized QA report.",
  "artifacts_from_cosmo_memory": {
    "schema": {
      "filename": "METADATA_SCHEMA.json",
      "known_relative_path_in_runtime_outputs": "runtime/outputs/code-creation/agent_1766614627659_92j3x3t/schemas/METADATA_SCHEMA.json",
      "known_size_bytes": 7292,
      "stated_purpose_from_memory": "JSON Schema for case studies; aligned to metadata requirements including rights/licensing and authoritative URLs (no downloads)."
    },
    "validator": {
      "filename": "schema_validate.py",
      "known_relative_path_in_runtime_outputs": "runtime/outputs/code-creation/agent_1766614627659_92j3x3t/src/utils/schema_validate.py",
      "known_size_bytes": 4541,
      "stated_purpose_from_memory": "Validate case-study JSON against the schema."
    },
    "related_cli": {
      "filename": "add_case_study.py",
      "known_relative_path_in_runtime_outputs": "runtime/outputs/code-creation/agent_1766614627659_92j3x3t/src/cli/add_case_study.py",
      "known_size_bytes": 7969,
      "stated_purpose_from_memory": "Writes a new case-study JSON/MD stub into /outputs/case_studies/ and validates it against the schema; includes fields for rights/licensing and authoritative URLs (no downloads)."
    },
    "qa_runner_evidence": {
      "filename": "qa_gate_runner.py",
      "evidence_from_memory": "A QA gate runner exists and computes ROOT by walking up to a parent containing 'config'. Full behavior and output paths are not present in memory."
    }
  },
  "run_context": {
    "validated_glob": "/outputs/case_studies/*",
    "output_path_required_by_mission": "/outputs/qa/schema_validation.json",
    "timestamp_utc": null
  },
  "results": {
    "files_discovered": null,
    "files_validated": null,
    "files_passed": null,
    "files_failed": null,
    "failures": [],
    "notes": [
      "COSMO memory provided artifact existence (paths/sizes/purpose) but not the schema contents, validator CLI interface, repository entrypoint, or case study JSON files.",
      "Populate 'results' with actual counts and per-file errors after executing schema_validate.py within the single-command QA run."
    ]
  }
}
```

This is **self-contained** and uses **only** facts provided in memory, while clearly delimiting unknowns.

---

## Human-readable summary for the normalized QA report (grounded text block)

Because the normalized QA report format/path is not provided in memory, the only grounded deliverable is the exact summary *content* that should be inserted wherever your normalized QA report is generated.

Use this block verbatim in the QA report:

### Schema validation (case studies)

- Schema artifact present: `METADATA_SCHEMA.json`  
  Source path (from COSMO memory): `runtime/outputs/code-creation/agent_1766614627659_92j3x3t/schemas/METADATA_SCHEMA.json` (7292 bytes)  
  Intended coverage (from COSMO memory): case-study metadata including rights/licensing and authoritative URLs (no downloads).
- Validator artifact present: `schema_validate.py`  
  Source path (from COSMO memory): `runtime/outputs/code-creation/agent_1766614627659_92j3x3t/src/utils/schema_validate.py` (4541 bytes)  
  Intended function (from COSMO memory): validate case-study JSON against the schema.
- Required output artifact written by the single-command QA run: `/outputs/qa/schema_validation.json`  
  (Populate this file with discovered/validated counts and any per-file schema errors after execution.)

---

## Conclusion

From the provided COSMO memory, the key concrete facts are that **`METADATA_SCHEMA.json`** (7292 bytes) and a corresponding validator **`schema_validate.py`** (4541 bytes) already exist, with explicit intent to validate case-study JSON metadata including **rights/licensing** and **authoritative URLs (no downloads)**. The mission’s remaining requirement is therefore *integration*: ensuring the single-command QA run invokes that validator across `/outputs/case_studies/*`, writes the mandated output file **`/outputs/qa/schema_validation.json`**, and includes the schema-validation summary text in the normalized QA report. The JSON and summary text above are the complete, grounded deliverables that can be saved and embedded once the validator step is executed in your environment.