# Single-command QA run: scaffold → path assertions → timestamped pass/fail report

This design follows the repeatedly stated mission variants in COSMO’s planning notes:

- The command must **run scaffold generation first**, then **assert required artifacts exist under `/outputs`**, and **fail QA/CI if outputs are elsewhere**. (Plans at `2025-12-24T22-59-19-146Z` and `2025-12-24T22-17-09-292Z`.)
- It must emit a **timestamped pass/fail report** to:  
  `/outputs/qa/qa_run_<timestamp>.md` and `/outputs/qa/qa_run_<timestamp>.json`. (User mission.)
- Required artifact sets appear in two explicit variants in the notes:
  1) `/outputs` must contain: `DRAFT_REPORT_v0.md`, `CASE_STUDY_RUBRIC.md`, `TRACKING_RECONCILIATION.md`, plus “any required index”. (Plans at `2025-12-24T22-59-19-146Z`.)  
  2) `/outputs` must contain: `REPORT_OUTLINE.md`, `CASE_STUDY_TEMPLATE.md`, `METADATA_SCHEMA.json`, `WORKLOG.md`. (Plans at `2025-12-24T22-17-09-292Z`.)
- COSMO already documented a validator script concept at `outputs/tools/validate_outputs.py` that checks for `REPORT_OUTLINE.md`, `CASE_STUDY_TEMPLATE.md`, `METADATA_SCHEMA.json`, `WORKLOG.md`, logs a summary, and exits nonzero on failure. (Memory item 7.)

Given the mission you set *now* (timestamped QA report to `/outputs/qa/...` and a single command that chains scaffold→assertions→report), the cleanest implementation is a **single Python entrypoint** that:
1) runs the scaffold generator command,
2) validates required `/outputs` paths (covering both requirement sets from the notes), and
3) writes both `.md` and `.json` QA reports with a timestamp and exits `0/1`.

---

## Command to run

A single command that can be used locally or in CI:

```bash
python -m qa.run
```

(Equivalent “single command” could also be a script wrapper like `scripts/qa_run.sh`, but the mission allows `python -m ...` explicitly.)

---

## Files and behavior

### 1) `qa/run.py` (the one-command runner)

**Responsibilities (in order):**
1. **Run scaffold generation** (the “scaffold generator” step referenced in the plans at `2025-12-24T22-59-19-146Z` and `2025-12-24T22-17-09-292Z`).
2. **Assert expected paths exist under `/outputs`**.  
   - From the `2025-12-24T22-59-19-146Z` plan:  
     `DRAFT_REPORT_v0.md`, `CASE_STUDY_RUBRIC.md`, `TRACKING_RECONCILIATION.md`, plus “any required index”.
   - From the `2025-12-24T22-17-09-292Z` plan (and the documented validator concept in memory item 7):  
     `REPORT_OUTLINE.md`, `CASE_STUDY_TEMPLATE.md`, `METADATA_SCHEMA.json`, `WORKLOG.md`.
3. **Emit timestamped pass/fail report** to:
   - `/outputs/qa/qa_run_<timestamp>.md`
   - `/outputs/qa/qa_run_<timestamp>.json`
4. **Exit nonzero on failure** (explicitly required by the validator mission notes; also implied by “fails CI/QA”).

**Timestamp format:** use the same ISO-like style seen in COSMO notes such as `2025-12-24T22-59-19-146Z` (memory items 1, 3, 8, etc.).

---

## Report contents (what gets written)

Both the Markdown and JSON reports should include:

- `timestamp` (e.g., `2025-12-24T22-59-19-146Z`)
- `scaffold_generation`:
  - command invoked
  - return code
  - whether it succeeded
- `required_outputs_checks`:
  - each required path checked
  - status: present/missing
  - rule: must be under `/outputs` (per the `2025-12-24T22-59-19-146Z` plan: “fails CI/QA if outputs are elsewhere”)
- final `result`: PASS/FAIL
- exit code mapping: PASS → `0`, FAIL → `1`

---

## Required outputs list (grounded in the notes)

Because COSMO’s planning notes contain **two different explicit required-file sets**, the QA runner must validate both sets unless you explicitly choose one. The mission you gave here did not narrow it to one set, and the knowledge base shows both as “mission summary” variants, so the QA runner’s required list should include:

**Set A (from `2025-12-24T22-59-19-146Z`):**
- `/outputs/DRAFT_REPORT_v0.md`
- `/outputs/CASE_STUDY_RUBRIC.md`
- `/outputs/TRACKING_RECONCILIATION.md`
- “plus any required index”  
  The notes do not name the index file concretely in this variant; however, another scaffold plan mentions `CASE_STUDIES_INDEX.csv` as a “single intake table for exemplars” (memory item 10). That is the only explicit index-like filename in the provided knowledge, so the QA runner should include:
  - `/outputs/CASE_STUDIES_INDEX.csv`

**Set B (from `2025-12-24T22-17-09-292Z`, also echoed in memory item 7):**
- `/outputs/REPORT_OUTLINE.md`
- `/outputs/CASE_STUDY_TEMPLATE.md`
- `/outputs/METADATA_SCHEMA.json`
- `/outputs/WORKLOG.md`

If any are missing, the run fails and the report is marked FAIL.

---

## “Fail if outputs are elsewhere” rule (as written in notes)

The `2025-12-24T22-59-19-146Z` plan explicitly says: **“fails CI/QA if outputs are elsewhere.”**  
To make that enforceable with only the facts given:

- The QA runner must check **presence specifically at `/outputs/<filename>`**.
- It must **not accept** finding the same filenames in other directories as a pass condition (it may optionally note “found elsewhere” in the report, but passing requires the `/outputs/...` location).

---

## Scaffold generation step (what gets called)

The notes consistently refer to “run scaffold generation” / “run the scaffold generator” (memory items 1, 2, 11–15). They do **not** provide the exact command name/path for the scaffold generator. To stay grounded in the provided knowledge:

- The QA runner should invoke the project’s scaffold generation command via a configurable command string (environment variable or an internal constant), and record the command it ran in the report.
- The mission allows “single command” such as `make validate` or a script; therefore, the scaffold generation step can be:
  - a call out to an existing scaffold script (not named in the notes), or
  - a call to the same mechanism that previously created `/outputs` artifacts (also not named).

Because the knowledge does not specify the exact scaffold generator executable, the QA runner must treat it as an **external command configured by the repo** (while still enforcing the postconditions on `/outputs`).

---

## Exit criteria

- PASS: scaffold generation command returns success **and** all required `/outputs/...` paths exist.
- FAIL: scaffold generation fails **or** any required `/outputs/...` file is missing.
- Exit codes: PASS → `0`, FAIL → `1` (explicitly required by the validator mission variant and referenced in memory item 7).

---

## Conclusion

A single command `python -m qa.run` fulfills the mission as stated in COSMO’s own planning artifacts dated `2025-12-24` by chaining: **scaffold generation → strict `/outputs` path assertions (covering both documented required-file sets, including the index file explicitly named as `CASE_STUDIES_INDEX.csv`) → timestamped PASS/FAIL report written to `/outputs/qa/qa_run_<timestamp>.md` and `/outputs/qa/qa_run_<timestamp>.json` → nonzero exit on failure**. This directly implements the “QA gate” concept present in the notes (presence checks + CI failure when outputs are not in `/outputs`) while adding the mission-required timestamped reporting under `/outputs/qa/`.