# Three comparative case studies using a renormalization / coarse-graining lens (COSMO-anchored, diagnostic-first)

This document drafts **three comparative case studies** (A–C) that are deliberately **methods- and diagnostics-centered**, consistent with COSMO’s consolidated findings:

- Build a **systematic, cross-validated diagnostic and benchmarking framework** for spin-foam/GFT renormalization that prioritizes **continuum-recovery observables and scaling metrics**, supported by **prototype numerical/symbolic toy RG flows and entanglement diagnostics**, so different coarse-graining/tensor-network approaches become **mutually comparable**. (Memory items **1**, **2**)
- Use **lightweight, reproducible toy experiments** with shared state/diagnostic utilities; export reusable code. (Item **2**)
- For continuum/infinite-volume extrapolation, use **global fits across multiple lattice spacings and volumes** to a **Symanzik-motivated continuum+finite-volume ansatz** with the **correct leading \(O(a^n)\)** term, set scales by a **common nonperturbative scale** (examples given: **Wilson-flow \(w_0/t_0\)**), and propagate the **full correlated covariance**; share **benchmark ensembles and blinded synthetic data** across codes to isolate residual systematics. (Item **3**)
- Use a unifying IO adapter that **normalizes heterogeneous RG/coarse-graining logs** into a sequence of **steps** with **scale information, couplings/parameters, observables, and optional distributional payloads** (from `rg_io.py` introspection). (Item **4**)
- Leverage the existing created package layout **`sf_gft_diagnostics`** (observables, scaling, metrics, rg_io, benchmarks, reporting, CLI entry). (Items **20**, **22**)
- Leverage a second small library that includes **graphs** and **quantum** utilities suitable for toy entanglement/decoherence diagnostics. (Item **23**)
- Provide **skeleton Jupyter notebooks** and **data manifests**; include a minimal computational plan (notebooks, datasets, resource needs).

Because COSMO memory does *not* provide domain-specific equations/details for (B) holographic RG vs asymptotic safety or (C) analogue-BEC experimental specifics, those case studies are framed as **comparative diagnostic pipelines** that ingest heterogeneous flows/measurements through the same normalization + benchmarking interfaces, using **blinded synthetic data** where real data is not specified (explicitly supported by item **3**).

---

## Shared infrastructure across all three case studies (the “diagnostics spine”)

### Shared objective
All three case studies will be made comparable by forcing them through the same diagnostic stages:

1. **Ingest/normalize** heterogeneous logs/outputs into a common “RG-step” dataset:
   - steps indexed by coarse-graining/RG iteration
   - each step includes:
     - **scale metadata**
     - **couplings/parameters**
     - **observables**
     - optional **distributional payloads**
   This is precisely the role described in the `rg_io.py` introspection: *“normalizes heterogeneous logs … into a simple in-memory dataset: a sequence of ‘steps’ with scale information, couplings/parameters, observables, and optional distributional payloads.”* (Item **4**)

2. **Compute continuum-recovery diagnostics** using a stable library of:
   - observables (`observables.py`)
   - scaling models / fits (`scaling.py`)
   - metrics (`metrics.py`)
   - benchmark datasets and blinded synthetic data hooks (`benchmarks.py`)
   - standardized report outputs (`reporting.py`)
   (Items **20**, **22**)

3. **Cross-validate** by:
   - running the same diagnostics across multiple coarse-graining approaches / codebases
   - using **shared benchmark ensembles** and **blinded synthetic data** to ensure that differences are systematic/physical rather than analysis choices (Item **3**)

4. **Perform global continuum/infinite-volume fits** where applicable:
   - Symanzik-motivated continuum + finite-volume ansatz
   - include **correct leading \(O(a^n)\)** term
   - use **common nonperturbative scale** such as Wilson-flow \(w_0/t_0\) as the memory’s concrete example
   - full **correlated covariance propagation**
   (Item **3**)

### Shared code assets referenced from COSMO memory

**Package A (diagnostics framework):** `sf_gft_diagnostics`
- `src/sf_gft_diagnostics/observables.py` (Item **20**)
- `src/sf_gft_diagnostics/scaling.py` (Item **20**)
- `src/sf_gft_diagnostics/metrics.py` (Item **20**)
- `src/sf_gft_diagnostics/rg_io.py` (Item **20**, plus introspection in **4**)
- `src/sf_gft_diagnostics/benchmarks.py` (Item **20**)
- `src/sf_gft_diagnostics/reporting.py` (Item **20**)
- `src/main.py` CLI entrypoint (Item **20**)
- `README.md`, `pyproject.toml` (Item **20**)

**Package B (toy quantum/graph utilities):**
- `src/lib/quantum.py` (Item **23**)
- `src/lib/graphs.py` (Item **23**)
- plus IO and plotting helpers (Item **23**)

**Metadata/CI discipline (optional but aligned with benchmarking):**
- a script to **record benchmark metadata**: `scripts/record_benchmark_metadata.py` (Item **26**)
- CI workflow exists in a separate artifact (Item **26**) and a “golden path” logging idea is documented in another report (Item **13**), but details are not required for the notebooks.

---

# Case Study (A): Spin-foam vs GFT continuum-recovery coarse-graining (comparative diagnostics and benchmarking)

## A1. Research question (diagnostic-first)
How do **spin-foam** and **group field theory (GFT)** coarse-graining pipelines compare when judged purely by **continuum-recovery observables and scaling metrics**, under a **single cross-validated diagnostic framework**?

This directly instantiates COSMO’s consolidated direction:
- prioritize **continuum-recovery observables and scaling metrics**
- make coarse-graining/tensor-network approaches **mutually comparable**
- support with **prototype numerical/symbolic toy experiments** (Items **1**, **2**)

## A2. Methods

### A2.1 Data model and IO normalization
We assume each approach produces a log of iterative coarse-graining / RG steps. We do not assume a shared native format. Instead, we normalize into the `rg_io.py` abstract structure:

- dataset = ordered list of `steps`
- each step contains:
  - **scale information**
  - **couplings/parameters**
  - **observables**
  - optional **distributional payloads**

This is explicitly what `rg_io.py` was created to do. (Item **4**, Item **20**)

**Implementation hook:** `sf_gft_diagnostics.rg_io` will host adapters:
- `load_spinfoam_log(...)`
- `load_gft_log(...)`
- `to_step_sequence(...)`

(Names are illustrative skeleton entrypoints; the key is that `rg_io.py` is the normalization layer per item **4**.)

### A2.2 Diagnostics: observables, scaling, metrics
Using `sf_gft_diagnostics` modules (Item **20**):

- **Observables**: computed or re-keyed from logs into a consistent observable namespace (from `observables.py`).
- **Scaling**: fit scaling behavior across coarse-graining steps; if discretization parameters exist, allow extrapolation routines (from `scaling.py`).
- **Metrics**: compare stability/consistency of flows, distances between trajectories, collapse under rescaling, etc. (from `metrics.py`).
- **Benchmarks**: use synthetic/blinded benchmark datasets (from `benchmarks.py`) to validate the pipeline and enable fair cross-code comparison. This aligns with COSMO’s instruction to share blinded synthetic data to diagnose systematics (Item **3**).
- **Reporting**: standardized tables/plots/artifacts (from `reporting.py`). (Item **20**)

### A2.3 Cross-validation protocol (the “benchmark sandwich”)
1. **Unit-test stage**: run on toy RG flows (generated) to verify invariances and that scaling fits recover planted exponents.
2. **Blinded synthetic stage**: two synthetic datasets, one labelled “spin-foam-like” and one “GFT-like”, with hidden parameter differences. Analysts only see the normalized step sequence.
3. **Real-log stage** (if/when available): ingest actual logs; preserve the same diagnostics and reporting.

This directly uses COSMO’s method: *“Share a small set of benchmark ensembles and blinded synthetic data between codes so cross-program differences diagnose residual systematics rather than analysis or scale choices.”* (Item **3**)

### A2.4 Continuum / infinite-volume extrapolation (if the data provide \(a\), \(L\))
Where multiple lattice spacings/volumes exist (or are emulated), apply COSMO’s specified best practice (Item **3**):

- **Global fits across multiple lattice spacings and volumes**
- Fit to **Symanzik-m