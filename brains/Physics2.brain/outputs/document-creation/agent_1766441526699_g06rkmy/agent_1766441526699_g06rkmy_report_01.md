# Three comparative case studies (A–C) using a renormalization / coarse‑graining lens  
**Constraint honored:** Everything below is built **only** from the facts in the provided COSMO memory: (i) COSMO’s “diagnostic-first, benchmark-artifact” methodology; (ii) RG/coarse‑graining as a unifying thread across QG programs (explicitly framed around ~2021 special‑issue/editorial mappings); (iii) analogue‑gravity (BEC) Hawking‑like emission/correlations with attention to robustness/systematics/backreaction; (iv) foundations/noise spectroscopy + dynamical decoupling with a gravity‑sensitive residual channel (scaling with gravitational potential differences); (v) causal‑set push toward QFT‑like observables (entanglement entropy, in‑in correlators/scattering); (vi) the existence of reusable code artifacts: `sf_gft_diagnostics` (observables/scaling/metrics/rg_io/benchmarks/reporting/CLI) and a second toy library containing `graphs.py` and `quantum.py`; (vii) the benchmark suite philosophy with JSON schema validation, deterministic I/O, hashing/serialization, tolerance policies, and CI/golden tests; (viii) a lattice-style continuum/infinite-volume extrapolation prescription (Symanzik‑motivated continuum+finite‑volume ansatz; global fits; common scale setting example \(w_0/t_0\); propagate full correlated covariance).  
**Deliberate limitation:** No program-specific formulas (spin‑foam amplitudes, explicit holographic RG equations, explicit asymptotic‑safety beta functions, etc.) are invented.

---

## Common infrastructure used by all three case studies

### Shared research stance (COSMO consolidated)
COSMO’s operational finding is that progress comes from **turning interpretive claims into end‑to‑end reproducible benchmark artifacts** with:

- explicit **schemas** for outputs,
- **deterministic I/O** and fixed serialization/hashing,
- **reference computations** (“golden” outputs) with numeric tolerance policies,
- robustness diagnostics against **noise**, **gauge/scheme**, and **coarse‑graining/regulator** choices,  
so different approaches become comparable and resistant to drift (Consolidated item **6**).

### Shared “cross‑approach comparability” layer
From the memory: a unifying IO adapter is required that normalizes heterogeneous RG/coarse‑graining logs into a sequence of **steps** with **scale info**, **couplings/parameters**, **observables**, and optional distributional payloads (item **4**), implemented by `sf_gft_diagnostics/rg_io.py` (item **23**).

### Shared continuum/infinite-volume inference protocol (imported from COSMO memory)
For continuum recovery / scaling comparisons (item **1**, plus item **3**):

- Use **global fits across multiple lattice spacings and volumes**.
- Fit to a **Symanzik‑motivated continuum+finite‑volume ansatz** with the correct leading \(O(a^n)\) term (the power \(n\) is not fixed in memory; it must be chosen as part of the design and recorded).
- Set scales by a **common nonperturbative scale**, with examples \(w_0\) or \(t_0\) from Wilson flow (explicitly cited as examples in memory).
- Propagate the **full correlated covariance** (no uncorrelated shortcuts).
- Share **benchmark ensembles** and/or **blinded synthetic data** across codes to isolate residual systematics (item **3**).

### Shared code artifacts available (explicit in memory)
- Package: `sf_gft_diagnostics` (items **20**, **22**, **23**, **25**):  
  `observables.py`, `scaling.py`, `metrics.py`, `rg_io.py`, `benchmarks.py`, `reporting.py`, `main.py`, with a `pyproject.toml` and README.
- Second toy library (item **26**):  
  `src/lib/graphs.py`, `src/lib/quantum.py`, plus plotting + IO utilities and a CLI.
- Benchmark/CI support artifacts exist (items **4**, **5**, **29**, **30**):  
  a benchmark spec `benchmarks_v0_1.md`, a `schema.json`, tools like `numeric_compare.py` and `benchmark_compare.py`, and scripts for metadata recording plus a CI workflow.

### Output contract (applies to all cases)
Every notebook below is designed to emit benchmark JSON artifacts validated against the shared `schema.json` described in memory (items **4**, **5**). Each case study produces:

1. **Normalized RG/coarse‑graining step log** (via `rg_io` adapter).
2. **Derived observables and scaling metrics** (via `observables`, `scaling`, `metrics`).
3. **Continuum/infinite-volume extrapolation fit artifacts** (global fits, correlated covariance).
4. **A benchmark JSON report** (schema‑validated; includes metadata hashes, environment info, and pass/fail checks with tolerances).

---

# Case Study A (10–15 pages target): Spin‑foam vs. GFT continuum recovery via coarse‑graining diagnostics

## A1. Comparative question (coarse‑graining lens)
Both spin‑foam and group field theory (GFT) approaches emphasize **continuum recovery via background‑independent renormalization/coarse‑graining** and diagnosing restoration of effective (diffeomorphism‑like) symmetries (from the benchmark spec memory context). COSMO’s unifying aim (item **1**) is to make different coarse‑graining/tensor‑network approaches **mutually comparable** by prioritizing:

- **continuum‑recovery observables** and
- **scaling metrics**,  
with cross‑validated diagnostics.

**The comparison in this case study is not “which theory is correct,”** but:  
> Do two coarse‑graining pipelines (one producing “spin‑foam‑style” logs, one “GFT‑style” logs) yield consistent continuum‑recovery scaling diagnostics under the same normalization and inference protocol?

This is explicitly aligned with COSMO’s limitation statement: small observable sets can’t decisively discriminate theories; the goal is a **robustness contract** across scheme/regulator/coarse‑graining choices (memory item **5**).

## A2. Methods

### A2.1 Data model: normalize both pipelines into a single step schema
Use `sf_gft_diagnostics.rg_io` to ingest two heterogeneous sources:

- **Spin‑foam coarse‑graining log** (synthetic or imported, but recorded in a deterministic JSON/CSV form).
- **GFT coarse‑graining / RG log** (synthetic or imported similarly).

Then normalize into the “sequence of steps” concept from memory item **4**:
- step index,
- scale metadata,
- couplings/parameters,
- observables,
- optional distribution payloads.

This enables common downstream diagnostics.

### A2.2 Diagnostics: continuum recovery as scaling + extrapolation
Compute (from `sf_gft_diagnostics.observables`, `scaling`, `metrics`):

- **Scaling metrics** across coarse‑graining steps (how observables evolve with step/scale).
- **Continuum/infinite-volume extrapolations** using COSMO’s prescribed global‑fit approach (item **3**):
  - multi‑resolution/multi‑volume fits,
  - Symanzik‑motivated continuum + finite‑volume ansatz,
  - correlated covariance propagation,
  - shared scale setting (example: \(w_0/t_0\), used here only as an explicit scale-setting *example* from memory—if not available in a dataset, the case study uses a stand‑in “nonperturbative scale” variable but documents the substitution).

### A2.3 Robustness protocol: blinded synthetic ensembles + cross-code comparison
Per item **3**, create:
- “blinded” synthetic datasets representing outputs of each pipeline under varying regulator/coarse‑graining choices.
- Evaluate whether the inferred continuum targets and scaling exponents are stable within tolerance bands and whether residuals exhibit scheme sensitivity.

Use numeric comparison tools (memory item **30**: `numeric_compare.py`, `benchmark_compare.py`) to:
- compare derived metrics across runs,
- enforce tolerance policies, and
- generate a pass/fail section in the benchmark JSON output.

### A2.4 Reproducibility & CI
Adhere to COSMO’s artifact engineering requirements (item **6**):
- deterministic I/O,
- explicit schema validation (pre‑commit/CI gate per memory),
- metadata collection (script in memory item **29** suggests `record_benchmark_metadata.py` exists),
- golden outputs for regression.

## A3. Expected results (what this case study is designed to show)
Because COSMO memory does **not** include program-specific amplitude formulas or known numerical targets, “expected results” are expressed as **diagnostic outcomes**:

1. **Successful normalization**: both spin‑foam and GFT logs can be mapped into a common step-based representation without losing required scale/coupling/observable context (item **4**).
2. **Comparable scaling curves**: once normalized, derived scaling metrics can be plotted/compared across pipelines using the same functions.
3. **Continuum-extrapolation stability**: global fits across multiple resolutions/volumes produce continuum estimates that are:
   - stable under resampling,
   - sensitive in traceable ways to regulator/coarse‑