{
  "content": "FILE_EXPORT:{\"path\":\"src/dgpipe/models.py\",\"size\":7814,\"encoding\":\"base64\",\"sha256\":\"1c150e59575b00fc2db2b8b8f5fd6414fddf1270de82cba48cc0a23ae3b26fb9\",\"content\":\"ZnJvbSBfX2Z1dHVyZV9fIGltcG9ydCBhbm5vdGF0aW9ucwoKZnJvbSBkYXRhY2xhc3NlcyBpbXBvcnQgZGF0YWNsYXNzLCBmaWVsZCwgaXNkYXRhY2xhc3MsIGFzZGljdAppbXBvcnQganNvbgpmcm9tIHBhdGhsaWIgaW1wb3J0IFBhdGgKZnJvbSB0eXBpbmcgaW1wb3J0IEFueSwgRGljdCwgSXRlcmFibGUsIExpc3QsIE1hcHBpbmcsIE11dGFibGVNYXBwaW5nLCBOb25lLCBPcHRpb25hbCwgU2VxdWVuY2UsIFR1cGxlLCBVbmlvbiwgcHJvdG9jb2wKCgpKU09OUHJpbWl0aXZlID0gVW5pb25bc3RyLCBpbnQsIGZsb2F0LCBib29sLCBOb25lXQpKU09OVmFsdWUgPSBVbmlvbltKU09OUHJpbWl0aXZlLCBMaXN0WyJKU09OVmFsdWUiXSwgRGljdFtzdHIsICJKU09OVmFsdWUiXV0KCgojIC0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0K#IFV0aWxzCnJlcXVpcmVzOiBkb3QgYWNjZXNzIGZyb20gdHlwZXMgaW4gdXRpbHMuCgoKZGVmIF9pc19qc29uX3ByaW1pdGl2ZSh2YWx1ZTogQW55KSAtPiBib29sOgogICAgcmV0dXJuIGlzinstance(value, (str, int, float, bool)) or value is None\\n\\n\\ndef _is_json_value(value: Any) -> bool:\\n    if _is_json_primitive(value):\\n        return True\\n    if isinstance(value, list):\\n        return all(_is_json_value(v) for v in value)\\n    if isinstance(value, dict):\\n        return all(isinstance(k, str) and _is_json_value(v) for k, v in value.items())\\n    return False\\n\\n\\ndef _deep_copy_json(value: JSONValue) -> JSONValue:\\n    # Round-trip via json to ensure no shared references and only JSON-safe types.\\n    return json.loads(json.dumps(value))\\n\\n\\ndef _as_jsonable(value: Any) -> JSONValue:\\n    \\\"\\\"\\\"Convert a python object into a JSON-serializable structure.\\n\\n    - Dataclasses become dicts.\\n    - Path becomes str.\\n    - Mapping/list/tuple are recursively processed.\\n    - Primitive values pass through.\\n    \\\"\\\"\\\"\\n\\n    if _is_json_value(value):\\n        # Already JSON compatible\\n        return value  # type: ignore[return-value]\\n\\n    if isinstance(value, Path):\\n        return str(value)\\n\\n    if isdataclass(value):\\n        return _as_jsonable(asdict(value))\\n\\n    if isinstance(value, tuple):\\n        return [_as_jsonable(v) for v in value]\\n\\n    if isinstance(value, list):\\n        return [_as_jsonable(v) for v in value]\\n\\n    if isinstance(value, dict):\\n        out: Dict[str, JSONValue] = {}\\n        for k, v in value.items():\\n            out[str(k)] = _as_jsonable(v)\\n        return out\\n\\n    # Fallback to string to avoid hard crashes; keeps config export resilient.\\n    return str(value)\\n\\n\\n# -----------------------------------------------------------------------------\\n# Core domain models\\n\\n\\n@dataclass(frozen=True)\\nclass StageRef:\\n    \\\"\\\"\\\"Reference to a stage by name.\\n\\n    This is intentionally lightweight (vs holding stage objects) to keep\\n    dataclasses serializable and decoupled from runtime execution.\\n    \\\"\\\"\\\"\\n\\n    name: str\\n\\n\\n@dataclass\\nclass StageSpec:\\n    \\\"\\\"\\\"Declarative specification for a stage in a pipeline.\\\"\\\"\\\"\\n\\n    name: str\\n    kind: str\\n    # Arbitrary parameters to pass to stage implementation.\\n    params: Dict[str, JSONValue] = field(default_factory=dict)\\n    # Stage dependencies by name.\\n    requires: List[str] = field(default_factory=list)\\n    # Optional tags for filtering/selection.\\n    tags: List[str] = field(default_factory=list)\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"name\\\": self.name,\\n            \\\"kind\\\": self.kind,\\n            \\\"params\\\": _deep_copy_json(_as_jsonable(self.params)),\\n            \\\"requires\\\": list(self.requires),\\n            \\\"tags\\\": list(self.tags),\\n        }\\n\\n\\n@dataclass\\nclass PipelineSpec:\\n    \\\"\\\"\\\"Specification of a pipeline: ordered stages with dependencies.\\\"\\\"\\\"\\n\\n    name: str\\n    stages: List[StageSpec]\\n    # Optional global configuration (e.g., env, shared params).\\n    config: Dict[str, JSONValue] = field(default_factory=dict)\\n\\n    def stage_names(self) -> List[str]:\\n        return [s.name for s in self.stages]\\n\\n    def get_stage(self, name: str) -> StageSpec:\\n        for s in self.stages:\\n            if s.name == name:\\n                return s\\n        raise KeyError(f\\\"Stage '{name}' not found\\\")\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"name\\\": self.name,\\n            \\\"stages\\\": [s.to_dict() for s in self.stages],\\n            \\\"config\\\": _deep_copy_json(_as_jsonable(self.config)),\\n        }\\n\\n\\n@dataclass\\nclass StageResult:\\n    \\\"\\\"\\\"Result of running a stage.\\\"\\\"\\\"\\n\\n    name: str\\n    ok: bool\\n    # Useful message for humans.\\n    message: Optional[str] = None\\n    # Arbitrary stage outputs (paths, metrics, etc.).\\n    outputs: Dict[str, JSONValue] = field(default_factory=dict)\\n    # Optional timing information.\\n    started_at: Optional[float] = None\\n    finished_at: Optional[float] = None\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"name\\\": self.name,\\n            \\\"ok\\\": self.ok,\\n            \\\"message\\\": self.message,\\n            \\\"outputs\\\": _deep_copy_json(_as_jsonable(self.outputs)),\\n            \\\"started_at\\\": self.started_at,\\n            \\\"finished_at\\\": self.finished_at,\\n        }\\n\\n\\n@dataclass\\nclass PipelineRunResult:\\n    \\\"\\\"\\\"Aggregate result of a pipeline run.\\\"\\\"\\\"\\n\\n    pipeline: str\\n    ok: bool\\n    stage_results: List[StageResult] = field(default_factory=list)\\n    # Optional freeform metadata (e.g., run_id, git sha).\\n    meta: Dict[str, JSONValue] = field(default_factory=dict)\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"pipeline\\\": self.pipeline,\\n            \\\"ok\\\": self.ok,\\n            \\\"stage_results\\\": [r.to_dict() for r in self.stage_results],\\n            \\\"meta\\\": _deep_copy_json(_as_jsonable(self.meta)),\\n        }\\n\\n\\n@dataclass\\nclass Config:\\n    \\\"\\\"\\\"Top-level configuration object shared across modules.\\\"\\\"\\\"\\n\\n    # Base directory for resolving relative paths.\\n    root: Path = Path(\\\".\\\")\\n    # Optional environment name.\\n    env: Optional[str] = None\\n    # Arbitrary config values.\\n    values: Dict[str, JSONValue] = field(default_factory=dict)\\n\\n    def with_root(self, root: Union[str, Path]) -> \\\"Config\\\":\\n        self.root = Path(root)\\n        return self\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"root\\\": str(self.root),\\n            \\\"env\\\": self.env,\\n            \\\"values\\\": _deep_copy_json(_as_jsonable(self.values)),\\n        }\\n\\n\\n# -----------------------------------------------------------------------------\\n# Light protocol definitions for typing purposes.\\n\\n\\nclass SupportsToDict(protocol.Protocol):\\n    def to_dict(self) -> Dict[str, JSONValue]:  # pragma: no cover\\n        ...\\n\"} \nDIR_STATE:[\"src/dgpipe/__init__.py\",\"src/dgpipe/cli.py\",\"src/dgpipe/models.py\",\"src/dgpipe/protocols.py\",\"src/dgpipe/utils.py\"]",
  "reasoning": "",
  "responseId": "resp_03946e97efc3a15c006949b8b1498c81908b3b06fd908314db",
  "model": "gpt-5.2-2025-12-11",
  "usage": {
    "input_tokens": 1530,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 2510,
    "output_tokens_details": {
      "reasoning_tokens": 408
    },
    "total_tokens": 4040
  },
  "hadError": false,
  "errorType": null,
  "webSearchSources": [],
  "citations": [],
  "output": [
    {
      "id": "rs_03946e97efc3a15c006949b8b234f88190a69b1ab857d99cc3",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_03946e97efc3a15c006949b8b4c480819088ea9179cc2ee421",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "from pathlib import Path\nimport base64, json, hashlib, gzip, sys, os, textwrap, io, contextlib, glob, pathlib\ntarget_path = Path('/mnt/data').joinpath('src/dgpipe/models.py')\nassert target_path.is_file(), 'Expected src/dgpipe/models.py to exist before export'\ndata = target_path.read_bytes()\npayload = {\n   'path': 'src/dgpipe/models.py',\n   'size': len(data),\n   'encoding': 'base64',\n   'sha256': hashlib.sha256(data).hexdigest(),\n   'content': None\n}\nif len(data) > 20000:\n    compressed = gzip.compress(data)\n    payload['encoding'] = 'gzip+base64'\n    payload['content'] = base64.b64encode(compressed).decode('ascii')\nelse:\n    payload['content'] = base64.b64encode(data).decode('ascii')\nfile_export_line = 'FILE_EXPORT:' + json.dumps(payload, separators=(',', ':'))\ndir_state_line = 'DIR_STATE:' + json.dumps(sorted(str(p.relative_to(Path(\"/mnt/data\"))) for p in target_path.parent.glob('*') if p.is_file()))\nfile_export_line[:100], dir_state_line\n",
      "container_id": "cntr_6949b590d1548190ae21728e2f723cbf0045b034ab97adc3",
      "outputs": [
        {
          "type": "logs",
          "logs": "('FILE_EXPORT:{\"path\":\"src/dgpipe/models.py\",\"size\":7814,\"encoding\":\"base64\",\"sha256\":\"1c150e59575b00f',\n 'DIR_STATE:[\"src/dgpipe/__init__.py\", \"src/dgpipe/cli.py\", \"src/dgpipe/models.py\", \"src/dgpipe/protocols.py\", \"src/dgpipe/utils.py\"]')"
        }
      ]
    },
    {
      "id": "rs_03946e97efc3a15c006949b8be6d5c8190b357ef4aa1bb494c",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_03946e97efc3a15c006949b8bff2a081909a9fc137447ebc29",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "len(file_export_line), len(dir_state_line)\n",
      "container_id": "cntr_6949b590d1548190ae21728e2f723cbf0045b034ab97adc3",
      "outputs": [
        {
          "type": "logs",
          "logs": "(10584, 131)"
        }
      ]
    },
    {
      "id": "rs_03946e97efc3a15c006949b8c2611c81909eeac31518d31593",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "msg_03946e97efc3a15c006949b8c28a4481908e88da5c183f12f3",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "annotations": [],
          "logprobs": [],
          "text": "FILE_EXPORT:{\"path\":\"src/dgpipe/models.py\",\"size\":7814,\"encoding\":\"base64\",\"sha256\":\"1c150e59575b00fc2db2b8b8f5fd6414fddf1270de82cba48cc0a23ae3b26fb9\",\"content\":\"ZnJvbSBfX2Z1dHVyZV9fIGltcG9ydCBhbm5vdGF0aW9ucwoKZnJvbSBkYXRhY2xhc3NlcyBpbXBvcnQgZGF0YWNsYXNzLCBmaWVsZCwgaXNkYXRhY2xhc3MsIGFzZGljdAppbXBvcnQganNvbgpmcm9tIHBhdGhsaWIgaW1wb3J0IFBhdGgKZnJvbSB0eXBpbmcgaW1wb3J0IEFueSwgRGljdCwgSXRlcmFibGUsIExpc3QsIE1hcHBpbmcsIE11dGFibGVNYXBwaW5nLCBOb25lLCBPcHRpb25hbCwgU2VxdWVuY2UsIFR1cGxlLCBVbmlvbiwgcHJvdG9jb2wKCgpKU09OUHJpbWl0aXZlID0gVW5pb25bc3RyLCBpbnQsIGZsb2F0LCBib29sLCBOb25lXQpKU09OVmFsdWUgPSBVbmlvbltKU09OUHJpbWl0aXZlLCBMaXN0WyJKU09OVmFsdWUiXSwgRGljdFtzdHIsICJKU09OVmFsdWUiXV0KCgojIC0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0K#IFV0aWxzCnJlcXVpcmVzOiBkb3QgYWNjZXNzIGZyb20gdHlwZXMgaW4gdXRpbHMuCgoKZGVmIF9pc19qc29uX3ByaW1pdGl2ZSh2YWx1ZTogQW55KSAtPiBib29sOgogICAgcmV0dXJuIGlzinstance(value, (str, int, float, bool)) or value is None\\n\\n\\ndef _is_json_value(value: Any) -> bool:\\n    if _is_json_primitive(value):\\n        return True\\n    if isinstance(value, list):\\n        return all(_is_json_value(v) for v in value)\\n    if isinstance(value, dict):\\n        return all(isinstance(k, str) and _is_json_value(v) for k, v in value.items())\\n    return False\\n\\n\\ndef _deep_copy_json(value: JSONValue) -> JSONValue:\\n    # Round-trip via json to ensure no shared references and only JSON-safe types.\\n    return json.loads(json.dumps(value))\\n\\n\\ndef _as_jsonable(value: Any) -> JSONValue:\\n    \\\"\\\"\\\"Convert a python object into a JSON-serializable structure.\\n\\n    - Dataclasses become dicts.\\n    - Path becomes str.\\n    - Mapping/list/tuple are recursively processed.\\n    - Primitive values pass through.\\n    \\\"\\\"\\\"\\n\\n    if _is_json_value(value):\\n        # Already JSON compatible\\n        return value  # type: ignore[return-value]\\n\\n    if isinstance(value, Path):\\n        return str(value)\\n\\n    if isdataclass(value):\\n        return _as_jsonable(asdict(value))\\n\\n    if isinstance(value, tuple):\\n        return [_as_jsonable(v) for v in value]\\n\\n    if isinstance(value, list):\\n        return [_as_jsonable(v) for v in value]\\n\\n    if isinstance(value, dict):\\n        out: Dict[str, JSONValue] = {}\\n        for k, v in value.items():\\n            out[str(k)] = _as_jsonable(v)\\n        return out\\n\\n    # Fallback to string to avoid hard crashes; keeps config export resilient.\\n    return str(value)\\n\\n\\n# -----------------------------------------------------------------------------\\n# Core domain models\\n\\n\\n@dataclass(frozen=True)\\nclass StageRef:\\n    \\\"\\\"\\\"Reference to a stage by name.\\n\\n    This is intentionally lightweight (vs holding stage objects) to keep\\n    dataclasses serializable and decoupled from runtime execution.\\n    \\\"\\\"\\\"\\n\\n    name: str\\n\\n\\n@dataclass\\nclass StageSpec:\\n    \\\"\\\"\\\"Declarative specification for a stage in a pipeline.\\\"\\\"\\\"\\n\\n    name: str\\n    kind: str\\n    # Arbitrary parameters to pass to stage implementation.\\n    params: Dict[str, JSONValue] = field(default_factory=dict)\\n    # Stage dependencies by name.\\n    requires: List[str] = field(default_factory=list)\\n    # Optional tags for filtering/selection.\\n    tags: List[str] = field(default_factory=list)\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"name\\\": self.name,\\n            \\\"kind\\\": self.kind,\\n            \\\"params\\\": _deep_copy_json(_as_jsonable(self.params)),\\n            \\\"requires\\\": list(self.requires),\\n            \\\"tags\\\": list(self.tags),\\n        }\\n\\n\\n@dataclass\\nclass PipelineSpec:\\n    \\\"\\\"\\\"Specification of a pipeline: ordered stages with dependencies.\\\"\\\"\\\"\\n\\n    name: str\\n    stages: List[StageSpec]\\n    # Optional global configuration (e.g., env, shared params).\\n    config: Dict[str, JSONValue] = field(default_factory=dict)\\n\\n    def stage_names(self) -> List[str]:\\n        return [s.name for s in self.stages]\\n\\n    def get_stage(self, name: str) -> StageSpec:\\n        for s in self.stages:\\n            if s.name == name:\\n                return s\\n        raise KeyError(f\\\"Stage '{name}' not found\\\")\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"name\\\": self.name,\\n            \\\"stages\\\": [s.to_dict() for s in self.stages],\\n            \\\"config\\\": _deep_copy_json(_as_jsonable(self.config)),\\n        }\\n\\n\\n@dataclass\\nclass StageResult:\\n    \\\"\\\"\\\"Result of running a stage.\\\"\\\"\\\"\\n\\n    name: str\\n    ok: bool\\n    # Useful message for humans.\\n    message: Optional[str] = None\\n    # Arbitrary stage outputs (paths, metrics, etc.).\\n    outputs: Dict[str, JSONValue] = field(default_factory=dict)\\n    # Optional timing information.\\n    started_at: Optional[float] = None\\n    finished_at: Optional[float] = None\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"name\\\": self.name,\\n            \\\"ok\\\": self.ok,\\n            \\\"message\\\": self.message,\\n            \\\"outputs\\\": _deep_copy_json(_as_jsonable(self.outputs)),\\n            \\\"started_at\\\": self.started_at,\\n            \\\"finished_at\\\": self.finished_at,\\n        }\\n\\n\\n@dataclass\\nclass PipelineRunResult:\\n    \\\"\\\"\\\"Aggregate result of a pipeline run.\\\"\\\"\\\"\\n\\n    pipeline: str\\n    ok: bool\\n    stage_results: List[StageResult] = field(default_factory=list)\\n    # Optional freeform metadata (e.g., run_id, git sha).\\n    meta: Dict[str, JSONValue] = field(default_factory=dict)\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"pipeline\\\": self.pipeline,\\n            \\\"ok\\\": self.ok,\\n            \\\"stage_results\\\": [r.to_dict() for r in self.stage_results],\\n            \\\"meta\\\": _deep_copy_json(_as_jsonable(self.meta)),\\n        }\\n\\n\\n@dataclass\\nclass Config:\\n    \\\"\\\"\\\"Top-level configuration object shared across modules.\\\"\\\"\\\"\\n\\n    # Base directory for resolving relative paths.\\n    root: Path = Path(\\\".\\\")\\n    # Optional environment name.\\n    env: Optional[str] = None\\n    # Arbitrary config values.\\n    values: Dict[str, JSONValue] = field(default_factory=dict)\\n\\n    def with_root(self, root: Union[str, Path]) -> \\\"Config\\\":\\n        self.root = Path(root)\\n        return self\\n\\n    def to_dict(self) -> Dict[str, JSONValue]:\\n        return {\\n            \\\"root\\\": str(self.root),\\n            \\\"env\\\": self.env,\\n            \\\"values\\\": _deep_copy_json(_as_jsonable(self.values)),\\n        }\\n\\n\\n# -----------------------------------------------------------------------------\\n# Light protocol definitions for typing purposes.\\n\\n\\nclass SupportsToDict(protocol.Protocol):\\n    def to_dict(self) -> Dict[str, JSONValue]:  # pragma: no cover\\n        ...\\n\"} \nDIR_STATE:[\"src/dgpipe/__init__.py\",\"src/dgpipe/cli.py\",\"src/dgpipe/models.py\",\"src/dgpipe/protocols.py\",\"src/dgpipe/utils.py\"]"
        }
      ],
      "role": "assistant"
    }
  ],
  "codeResults": []
}