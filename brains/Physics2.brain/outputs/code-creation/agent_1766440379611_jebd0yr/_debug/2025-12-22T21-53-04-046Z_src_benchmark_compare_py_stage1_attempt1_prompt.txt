You are inside the OpenAI code interpreter environment with filesystem access to /mnt/data.

Mission summary: Define and implement a numeric-comparison utility (absolute/relative tolerances per observable, seeded randomness rules, deterministic ordering) and patch only what is necessary so `pytest` passes and `benchmark_case_001` matches `expected.json` within the specified tolerances.
Project: generated_script_1766440382703 (json script)

Target file details:
- Path: src/benchmark_compare.py
- Purpose: Updates the benchmark comparison entrypoint to use the numeric-comparison utility so pytest passes and benchmark_case_001 matches expected.json within specified tolerances with deterministic behavior.
- Category: source

Other planned files (for context only):
- src/numeric_compare.py: Implements a deterministic numeric-comparison utility supporting absolute/relative tolerances per observable, stable ordering, and seeded randomness rules for any tie-breaking needed during comparison.

Reference insights:
- [INTROSPECTION] 2025-12-22T21-50-52-344Z_src_benchmark_compare_py_stage1_attempt1_prompt.txt from code-creation agent agent_1766440246816_i1
- [AGENT: agent_1766432552135_37yovma] {"agentId":"agent_1766432552135_37yovma","goalId":"goal_guided_code_creation_1766429554815","containerI
- [AGENT: agent_1766430411939_w8zvs5v] {"agentId":"agent_1766430411939_w8zvs5v","goalId":"goal_guided_code_creation_1766429554815","containerI
- [AGENT: agent_1766438283976_puyw9gc] {"agentId":"agent_1766438283976_puyw9gc","goalId":"routing_code_1766438283975_nh5nje8","containerId":"c
- [AGENT: agent_1766438409884_82yeh6g] {"agentId":"agent_1766438409884_82yeh6g","goalId":"goal_7","containerId":"cntr_6949b60f62d4819083834ab5

Stage details:
- Stage: Stage 1
- Mode: create
- Goal: Updates the benchmark comparison entrypoint to use the numeric-comparison utility so pytest passes and benchmark_case_001 matches expected.json within specified tolerances with deterministic behavior.
- Line budget for this stage: <= 150 new/changed lines.

Implementation tasks (execute using Python in this environment):
1. from pathlib import Path
2. import json
3. target_path = Path('/mnt/data').joinpath('src/benchmark_compare.py')
4. target_path.parent.mkdir(parents=True, exist_ok=True)
5. Build the entire stage deliverable (<= 150 lines) as a list named chunks where each item is a multiline string representing a contiguous block of code without leading or trailing blank lines.
6. final_text = '\n'.join(block.strip('\n') for block in chunks).strip() + '\n'
7. target_path.write_text(final_text, encoding='utf-8')
8. print('FILE_WRITTEN:src/benchmark_compare.py')
9. print('DIR_STATE:' + json.dumps(sorted(str(p.relative_to(Path("/mnt/data"))) for p in target_path.parent.glob('*') if p.is_file())))

Constraints:
- Ensure the new file fully satisfies the stage goal with no placeholders or TODO markers.
- Keep the newly written code within the stated line/character budget.
- Keep console output short (only FILE_WRITTEN / DIR_STATE plus essential status).
- Do not touch files outside src/benchmark_compare.py.
- After writing the file, provide a one-sentence summary. Do not list the file contents in the final message.
