{
  "content": "FILE_EXPORT:{\"path\":\"src/experiments/toy_ising_emergent_classicality.py\",\"size\":5886,\"encoding\":\"base64\",\"sha256\":\"4fdd7a8ea3c3e5c100b4b5ddfe591b81605fe491bf356f0eb3c6a22defc7bd2d\",\"content\":\"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 bCwgal0NCiAgICBkb3duID0gc3BpbnNbKGkgKyAxKSAlIGwsIGpdDQogICAgbGVmdCA9IHNwaW5zW2ksIChqIC0gMSkgJSBsXQ0KICAgIHJpZ2h0ID0gc3BpbnNbaSwgKGogKyAxKSAlIGxdDQogICAgcmV0dXJuIGludCh1cCArIGRvd24gKyBsZWZ0ICsgcmlnaHQpDQoNCg0KZGVmIHRvdGFsX2VuZXJneShzcGluczogbnAubmRhcnJheSwgajogZmxvYXQsIGg6IGZsb2F0ID0gMC4wKSAtPiBmbG9hdDoNCiAgICAiIiJDb21wdXRlIHRvdGFsIGVuZXJneSBmb3IgMkQgSXNpbmcgd2l0aCBwZXJpb2RpYyBib3VuZGFyaWVzLg0KDQogICAgSD0tSiBzdW1f<ij> s_i s_j - h sum_i s_i. We count each bond once by summing right and down neighbors.\n    \"\"\"\n    l = spins.shape[0]\n    e = 0.0\n    # bond energy\n    for i in range(l):\n        for j_idx in range(l):\n            s = spins[i, j_idx]\n            e -= j * s * spins[i, (j_idx + 1) % l]\n            e -= j * s * spins[(i + 1) % l, j_idx]\n    # field term\n    if h != 0.0:\n        e -= h * float(spins.sum())\n    return e\n\n\ndef metropolis_sweep(\n    spins: np.ndarray,\n    beta: float,\n    j: float,\n    h: float,\n    noise_flip_prob: float = 0.0,\n) -> None:\n    \"\"\"One Metropolis sweep over all sites with an extra independent 'noise flip' channel.\n\n    The 'noise_flip_prob' is meant as a toy decoherence proxy: with probability p, flip the chosen spin\n    irrespective of energy (infinite-temperature kick).\n    \"\"\"\n    l = spins.shape[0]\n    # visit sites in random order\n    indices = [(i, j_idx) for i in range(l) for j_idx in range(l)]\n    random.shuffle(indices)\n\n    for (i, j_idx) in indices:\n        if noise_flip_prob > 0.0 and random.random() < noise_flip_prob:\n            spins[i, j_idx] *= -1\n            continue\n\n        s = spins[i, j_idx]\n        nb = neighbor_sum(spins, i, j_idx)\n        # Delta E for flipping s_i: 2*s_i*(J*sum_nb + h)\n        dE = 2.0 * s * (j * nb + h)\n        if dE <= 0.0:\n            spins[i, j_idx] = -s\n        else:\n            if random.random() < math.exp(-beta * dE):\n                spins[i, j_idx] = -s\n\n\ndef correlation_length_proxy(spins: np.ndarray) -> float:\n    \"\"\"Cheap proxy: average nearest-neighbor correlation.\"\"\"\n    l = spins.shape[0]\n    s = spins\n    corr = 0.0\n    n = 0\n    for i in range(l):\n        for j_idx in range(l):\n            corr += s[i, j_idx] * s[i, (j_idx + 1) % l]\n            corr += s[i, j_idx] * s[(i + 1) % l, j_idx]\n            n += 2\n    return float(corr / n)\n\n\ndef entropy_like_from_magnetization_hist(mags: list[float], bins: int = 41) -> float:\n    \"\"\"Shannon entropy of magnetization histogram (coarse proxy for 'classicality'/order).\"\"\"\n    if len(mags) == 0:\n        return float(\"nan\")\n    mags_arr = np.asarray(mags, dtype=float)\n    hist, _ = np.histogram(mags_arr, bins=bins, range=(-1.0, 1.0), density=False)\n    p = hist.astype(float)\n    p /= p.sum()\n    p = p[p > 0]\n    return float(-(p * np.log(p)).sum())\n\n\ndef run_single_point(cfg: RunConfig, temp: float, noise: float) -> dict:\n    \"\"\"Run at a single (T, noise) and return diagnostics.\"\"\"\n    spins = init_spins(cfg.l)\n    beta = 1.0 / temp\n\n    # thermalize\n    for _ in range(cfg.thermalization_sweeps):\n        metropolis_sweep(spins, beta=beta, j=cfg.j, h=cfg.h, noise_flip_prob=noise)\n\n    mags: list[float] = []\n    energies: list[float] = []\n    corrs: list[float] = []\n\n    total_sweeps = cfg.sweeps_per_step\n    for sweep in range(total_sweeps):\n        metropolis_sweep(spins, beta=beta, j=cfg.j, h=cfg.h, noise_flip_prob=noise)\n        if (sweep + 1) % cfg.measurement_every == 0:\n            m = float(spins.sum()) / float(cfg.l * cfg.l)\n            e = total_energy(spins, j=cfg.j, h=cfg.h) / float(cfg.l * cfg.l)\n            c = correlation_length_proxy(spins)\n            mags.append(m)\n            energies.append(e)\n            corrs.append(c)\n\n    mags_arr = np.asarray(mags, dtype=float)\n    energies_arr = np.asarray(energies, dtype=float)\n    corrs_arr = np.asarray(corrs, dtype=float)\n\n    out = {\n        \"T\": temp,\n        \"noise\": noise,\n        \"m_mean\": float(mags_arr.mean()),\n        \"m_abs_mean\": float(np.abs(mags_arr).mean()),\n        \"m_std\": float(mags_arr.std(ddof=1)) if len(mags_arr) > 1 else 0.0,\n        \"e_mean\": float(energies_arr.mean()),\n        \"e_std\": float(energies_arr.std(ddof=1)) if len(energies_arr) > 1 else 0.0,\n        \"corr_nn_mean\": float(corrs_arr.mean()),\n        \"corr_nn_std\": float(corrs_arr.std(ddof=1)) if len(corrs_arr) > 1 else 0.0,\n        \"entropy_mag\": entropy_like_from_magnetization_hist(mags),\n        \"n_meas\": int(len(mags)),\n    }\n    return out\n\n\ndef make_schedules(cfg: RunConfig) -> tuple[np.ndarray, np.ndarray]:\n    temps = np.linspace(cfg.temp_min, cfg.temp_max, cfg.temp_steps)\n    noises = np.linspace(cfg.noise_min, cfg.noise_max, cfg.noise_steps)\n    return temps, noises\n\n\ndef plot_heatmaps(cfg: RunConfig, results: list[dict], outdir: Path) -> None:\n    import matplotlib.pyplot as plt\n\n    temps, noises = make_schedules(cfg)\n    # reshape results into grids\n    shape = (len(noises), len(temps))\n    key_list = [\"m_abs_mean\", \"corr_nn_mean\", \"entropy_mag\"]\n    grids = {}\n    for k in key_list:\n        grids[k] = np.zeros(shape, dtype=float)\n\n    # index mapping\n    idx = {(r[\"noise\"], r[\"T\"]): r for r in results}\n    for ni, n in enumerate(noises):\n        for ti, t in enumerate(temps):\n            r = idx[(float(n), float(t))]\n            for k in key_list:\n                grids[k][ni, ti] = r[k]\n\n    def save_heatmap(key: str, title: str, cmap: str = \"viridis\") -> None:\n        fig, ax = plt.subplots(figsize=(7.2, 4.2))\n        im = ax.imshow(\n            grids[key],\n            origin=\"lower\",\n            aspect=\"auto\",\n            extent=[temps[0], temps[-1], noises[0], noises[-1]],\n            cmap=cmap,\n        )\n        ax.set_xlabel(\"Temperature T\")\n        ax.set_ylabel(\"Noise flip prob\")\n        ax.set_title(title)\n        fig.colorbar(im, ax=ax, shrink=0.9)\n        fig.tight_layout()\n        fig.savefig(outdir / f\"heatmap_{key}.png\", dpi=160)\n        plt.close(fig)\n\n    save_heatmap(\"m_abs_mean\", \"|m| mean\", cmap=\"magma\")\n    save_heatmap(\"corr_nn_mean\", \"Nearest-neighbor corr mean\", cmap=\"viridis\")\n    save_heatmap(\"entropy_mag\", \"Entropy(m) (hist)\", cmap=\"cividis\")\n\n    if cfg.show_plots:\n        # Optional: show last heatmap\n        import matplotlib.pyplot as plt  # noqa: F811\n\n        img = plt.imread(outdir / \"heatmap_m_abs_mean.png\")\n        plt.figure(figsize=(7, 4))\n        plt.imshow(img)\n        plt.axis(\"off\")\n        plt.show()\n\n\ndef main() -> None:\n    ap = argparse.ArgumentParser(description=\"Toy 2D Ising emergent classicality proxy experiment.\")\n    ap.add_argument(\"--l\", type=int, default=16)\n    ap.add_argument(\"--sweeps-per-step\", type=int, default=300)\n    ap.add_argument(\"--thermalization-sweeps\", type=int, default=200)\n    ap.add_argument(\"--measurement-every\", type=int, default=10)\n    ap.add_argument(\"--seed\", type=int, default=0)\n    ap.add_argument(\"--j\", type=float, default=1.0)\n    ap.add_argument(\"--h\", type=float, default=0.0)\n    ap.add_argument(\"--temp-min\", type=float, default=0.5)\n    ap.add_argument(\"--temp-max\", type=float, default=4.0)\n    ap.add_argument(\"--temp-steps\", type=int, default=13)\n    ap.add_argument(\"--noise-min\", type=float, default=0.0)\n    ap.add_argument(\"--noise-max\", type=float, default=0.6)\n    ap.add_argument(\"--noise-steps\", type=int, default=7)\n    ap.add_argument(\"--outdir\", type=str, default=\"out/toy_ising_emergent_classicality\")\n    ap.add_argument(\"--no-save-plots\", action=\"store_true\")\n    ap.add_argument(\"--show-plots\", action=\"store_true\")\n    ap.add_argument(\"--quiet\", action=\"store_true\")\n    args = ap.parse_args()\n\n    cfg = RunConfig(\n        l=args.l,\n        sweeps_per_step=args.sweeps_per_step,\n        thermalization_sweeps=args.thermalization_sweeps,\n        measurement_every=args.measurement_every,\n        seed=args.seed,\n        j=args.j,\n        h=args.h,\n        temp_min=args.temp_min,\n        temp_max=args.temp_max,\n        temp_steps=args.temp_steps,\n        noise_min=args.noise_min,\n        noise_max=args.noise_max,\n        noise_steps=args.noise_steps,\n        outdir=args.outdir,\n        save_plots=(not args.no_save_plots),\n        show_plots=args.show_plots,\n        verbose=(not args.quiet),\n    )\n\n    set_seeds(cfg.seed)\n    outdir = Path(\"/mnt/data\") / cfg.outdir\n    outdir.mkdir(parents=True, exist_ok=True)\n\n    temps, noises = make_schedules(cfg)\n    if cfg.verbose:\n        print(f\"Grid: {len(temps)} temps x {len(noises)} noises = {len(temps)*len(noises)} points\")\n        print(f\"Output: {outdir}\")\n\n    results: list[dict] = []\n    for n in noises:\n        for t in temps:\n            r = run_single_point(cfg, temp=float(t), noise=float(n))\n            results.append(r)\n            if cfg.verbose:\n                print(\n                    f\"T={r['T']:.3f} noise={r['noise']:.3f} |m|={r['m_abs_mean']:.3f} \"\n                    f\"corr={r['corr_nn_mean']:.3f} Hm={r['entropy_mag']:.3f}\"\n                )\n\n    # save json\n    meta = {\"config\": asdict(cfg), \"results\": results}\n    (outdir / \"results.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n\n    if cfg.save_plots:\n        plot_heatmaps(cfg, results, outdir)\n\n    if cfg.verbose:\n        print(\"Done.\")\n\n\nif __name__ == \"__main__\":\n    main()\n\"}\nDIR_STATE:[\"src/experiments/symbolic_rg_phi4.py\",\"src/experiments/toy_ising_emergent_classicality.py\"]",
  "reasoning": "",
  "responseId": "resp_0f4deaf4d661b04f0069499a11be608194ba1ced94b625d800",
  "model": "gpt-5.2-2025-12-11",
  "usage": {
    "input_tokens": 2183,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 5843,
    "output_tokens_details": {
      "reasoning_tokens": 625
    },
    "total_tokens": 8026
  },
  "hadError": false,
  "errorType": null,
  "webSearchSources": [],
  "citations": [],
  "output": [
    {
      "id": "ci_0f4deaf4d661b04f0069499a12ad90819493992fa4eda09d1e",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "from pathlib import Path\nimport base64, json, hashlib, gzip\n\ntarget_path = Path('/mnt/data').joinpath('src/experiments/toy_ising_emergent_classicality.py')\nassert target_path.is_file(), 'Expected src/experiments/toy_ising_emergent_classicality.py to exist before export'\ndata = target_path.read_bytes()\npayload = {\n  'path': 'src/experiments/toy_ising_emergent_classicality.py',\n  'size': len(data),\n  'encoding': 'base64',\n  'sha256': hashlib.sha256(data).hexdigest(),\n  'content': None\n}\nif len(data) > 20000:\n    compressed = gzip.compress(data)\n    payload['encoding'] = 'gzip+base64'\n    payload['content'] = base64.b64encode(compressed).decode('ascii')\nelse:\n    payload['content'] = base64.b64encode(data).decode('ascii')\n\nprint('FILE_EXPORT:' + json.dumps(payload, separators=(',', ':')))\nprint('DIR_STATE:' + json.dumps(sorted(str(p.relative_to(Path(\"/mnt/data\"))) for p in target_path.parent.glob('*') if p.is_file())))",
      "container_id": "cntr_694996cf1f0881908fd6ebe4e5dd54140c8f193d7d2aa5f8",
      "outputs": []
    },
    {
      "id": "rs_0f4deaf4d661b04f0069499a16e5148194b4ae43561b1ea269",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_0f4deaf4d661b04f0069499a17f2288194a83ab7d0b7a18f20",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "from pathlib import Path\ntarget_path = Path('/mnt/data/src/experiments/toy_ising_emergent_classicality.py')\nprint(target_path, target_path.exists(), target_path.is_file())\n",
      "container_id": "cntr_694996cf1f0881908fd6ebe4e5dd54140c8f193d7d2aa5f8",
      "outputs": [
        {
          "type": "logs",
          "logs": "/mnt/data/src/experiments/toy_ising_emergent_classicality.py True True\n"
        }
      ]
    },
    {
      "id": "rs_0f4deaf4d661b04f0069499a1a9b388194bfaf442a62e8df8d",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_0f4deaf4d661b04f0069499a1c646081948db5e782fa6f4ea9",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "from pathlib import Path\nimport os\np=Path('/mnt/data/src/experiments/toy_ising_emergent_classicality.py')\nprint(p.stat().st_size)\n",
      "container_id": "cntr_694996cf1f0881908fd6ebe4e5dd54140c8f193d7d2aa5f8",
      "outputs": []
    },
    {
      "id": "rs_0f4deaf4d661b04f0069499a1ee0608194a5d5d1dba15df6fa",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_0f4deaf4d661b04f0069499a21559c81949cad074a5cd64d70",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "from pathlib import Path\nimport base64, json, hashlib, gzip\ntarget_path = Path('/mnt/data/src/experiments/toy_ising_emergent_classicality.py')\ndata = target_path.read_bytes()\nlen(data), hashlib.sha256(data).hexdigest()[:10]\n",
      "container_id": "cntr_694996cf1f0881908fd6ebe4e5dd54140c8f193d7d2aa5f8",
      "outputs": []
    },
    {
      "id": "rs_0f4deaf4d661b04f0069499b2f749081948cfa302c47f70844",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_0f4deaf4d661b04f0069499b3029e081948f8b06817bc402ba",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "1+1\n",
      "container_id": "cntr_694996cf1f0881908fd6ebe4e5dd54140c8f193d7d2aa5f8",
      "outputs": [
        {
          "type": "logs",
          "logs": "2"
        }
      ]
    },
    {
      "id": "rs_0f4deaf4d661b04f0069499b31cd98819489c63b2a02c71a09",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_0f4deaf4d661b04f0069499b32b3308194a35ac77f7b5c7cd8",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "from pathlib import Path, PurePosixPath\np=Path('/mnt/data/src/experiments/toy_ising_emergent_classicality.py')\np.exists(), p.is_file(), p.stat().st_size\n",
      "container_id": "cntr_694996cf1f0881908fd6ebe4e5dd54140c8f193d7d2aa5f8",
      "outputs": [
        {
          "type": "logs",
          "logs": "(True, True, 5886)"
        }
      ]
    },
    {
      "id": "rs_0f4deaf4d661b04f0069499b353fc48194bb3a74b58e8d403a",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_0f4deaf4d661b04f0069499b3671008194a6476396242a8906",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "import base64, json, hashlib, gzip\nfrom pathlib import Path\ntarget_path = Path('/mnt/data/src/experiments/toy_ising_emergent_classicality.py')\ndata = target_path.read_bytes()\npayload = {\n   'path': 'src/experiments/toy_ising_emergent_classicality.py',\n   'size': len(data),\n   'encoding': 'base64',\n   'sha256': hashlib.sha256(data).hexdigest(),\n   'content': base64.b64encode(data).decode('ascii')\n}\nfile_export_line = 'FILE_EXPORT:' + json.dumps(payload, separators=(',', ':'))\ndir_state = sorted(str(p.relative_to(Path(\"/mnt/data\"))) for p in target_path.parent.glob('*') if p.is_file())\ndir_state_line = 'DIR_STATE:' + json.dumps(dir_state)\nlen(file_export_line), len(dir_state_line), dir_state\n",
      "container_id": "cntr_694996cf1f0881908fd6ebe4e5dd54140c8f193d7d2aa5f8",
      "outputs": [
        {
          "type": "logs",
          "logs": "(8042,\n 103,\n ['src/experiments/symbolic_rg_phi4.py',\n  'src/experiments/toy_ising_emergent_classicality.py'])"
        }
      ]
    },
    {
      "id": "rs_0f4deaf4d661b04f0069499b3a93a88194b793fab572ea1815",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "msg_0f4deaf4d661b04f0069499b3ae4b08194829d462f0369f75d",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "annotations": [],
          "logprobs": [],
          "text": "FILE_EXPORT:{\"path\":\"src/experiments/toy_ising_emergent_classicality.py\",\"size\":5886,\"encoding\":\"base64\",\"sha256\":\"4fdd7a8ea3c3e5c100b4b5ddfe591b81605fe491bf356f0eb3c6a22defc7bd2d\",\"content\":\"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 bCwgal0NCiAgICBkb3duID0gc3BpbnNbKGkgKyAxKSAlIGwsIGpdDQogICAgbGVmdCA9IHNwaW5zW2ksIChqIC0gMSkgJSBsXQ0KICAgIHJpZ2h0ID0gc3BpbnNbaSwgKGogKyAxKSAlIGxdDQogICAgcmV0dXJuIGludCh1cCArIGRvd24gKyBsZWZ0ICsgcmlnaHQpDQoNCg0KZGVmIHRvdGFsX2VuZXJneShzcGluczogbnAubmRhcnJheSwgajogZmxvYXQsIGg6IGZsb2F0ID0gMC4wKSAtPiBmbG9hdDoNCiAgICAiIiJDb21wdXRlIHRvdGFsIGVuZXJneSBmb3IgMkQgSXNpbmcgd2l0aCBwZXJpb2RpYyBib3VuZGFyaWVzLg0KDQogICAgSD0tSiBzdW1f<ij> s_i s_j - h sum_i s_i. We count each bond once by summing right and down neighbors.\n    \"\"\"\n    l = spins.shape[0]\n    e = 0.0\n    # bond energy\n    for i in range(l):\n        for j_idx in range(l):\n            s = spins[i, j_idx]\n            e -= j * s * spins[i, (j_idx + 1) % l]\n            e -= j * s * spins[(i + 1) % l, j_idx]\n    # field term\n    if h != 0.0:\n        e -= h * float(spins.sum())\n    return e\n\n\ndef metropolis_sweep(\n    spins: np.ndarray,\n    beta: float,\n    j: float,\n    h: float,\n    noise_flip_prob: float = 0.0,\n) -> None:\n    \"\"\"One Metropolis sweep over all sites with an extra independent 'noise flip' channel.\n\n    The 'noise_flip_prob' is meant as a toy decoherence proxy: with probability p, flip the chosen spin\n    irrespective of energy (infinite-temperature kick).\n    \"\"\"\n    l = spins.shape[0]\n    # visit sites in random order\n    indices = [(i, j_idx) for i in range(l) for j_idx in range(l)]\n    random.shuffle(indices)\n\n    for (i, j_idx) in indices:\n        if noise_flip_prob > 0.0 and random.random() < noise_flip_prob:\n            spins[i, j_idx] *= -1\n            continue\n\n        s = spins[i, j_idx]\n        nb = neighbor_sum(spins, i, j_idx)\n        # Delta E for flipping s_i: 2*s_i*(J*sum_nb + h)\n        dE = 2.0 * s * (j * nb + h)\n        if dE <= 0.0:\n            spins[i, j_idx] = -s\n        else:\n            if random.random() < math.exp(-beta * dE):\n                spins[i, j_idx] = -s\n\n\ndef correlation_length_proxy(spins: np.ndarray) -> float:\n    \"\"\"Cheap proxy: average nearest-neighbor correlation.\"\"\"\n    l = spins.shape[0]\n    s = spins\n    corr = 0.0\n    n = 0\n    for i in range(l):\n        for j_idx in range(l):\n            corr += s[i, j_idx] * s[i, (j_idx + 1) % l]\n            corr += s[i, j_idx] * s[(i + 1) % l, j_idx]\n            n += 2\n    return float(corr / n)\n\n\ndef entropy_like_from_magnetization_hist(mags: list[float], bins: int = 41) -> float:\n    \"\"\"Shannon entropy of magnetization histogram (coarse proxy for 'classicality'/order).\"\"\"\n    if len(mags) == 0:\n        return float(\"nan\")\n    mags_arr = np.asarray(mags, dtype=float)\n    hist, _ = np.histogram(mags_arr, bins=bins, range=(-1.0, 1.0), density=False)\n    p = hist.astype(float)\n    p /= p.sum()\n    p = p[p > 0]\n    return float(-(p * np.log(p)).sum())\n\n\ndef run_single_point(cfg: RunConfig, temp: float, noise: float) -> dict:\n    \"\"\"Run at a single (T, noise) and return diagnostics.\"\"\"\n    spins = init_spins(cfg.l)\n    beta = 1.0 / temp\n\n    # thermalize\n    for _ in range(cfg.thermalization_sweeps):\n        metropolis_sweep(spins, beta=beta, j=cfg.j, h=cfg.h, noise_flip_prob=noise)\n\n    mags: list[float] = []\n    energies: list[float] = []\n    corrs: list[float] = []\n\n    total_sweeps = cfg.sweeps_per_step\n    for sweep in range(total_sweeps):\n        metropolis_sweep(spins, beta=beta, j=cfg.j, h=cfg.h, noise_flip_prob=noise)\n        if (sweep + 1) % cfg.measurement_every == 0:\n            m = float(spins.sum()) / float(cfg.l * cfg.l)\n            e = total_energy(spins, j=cfg.j, h=cfg.h) / float(cfg.l * cfg.l)\n            c = correlation_length_proxy(spins)\n            mags.append(m)\n            energies.append(e)\n            corrs.append(c)\n\n    mags_arr = np.asarray(mags, dtype=float)\n    energies_arr = np.asarray(energies, dtype=float)\n    corrs_arr = np.asarray(corrs, dtype=float)\n\n    out = {\n        \"T\": temp,\n        \"noise\": noise,\n        \"m_mean\": float(mags_arr.mean()),\n        \"m_abs_mean\": float(np.abs(mags_arr).mean()),\n        \"m_std\": float(mags_arr.std(ddof=1)) if len(mags_arr) > 1 else 0.0,\n        \"e_mean\": float(energies_arr.mean()),\n        \"e_std\": float(energies_arr.std(ddof=1)) if len(energies_arr) > 1 else 0.0,\n        \"corr_nn_mean\": float(corrs_arr.mean()),\n        \"corr_nn_std\": float(corrs_arr.std(ddof=1)) if len(corrs_arr) > 1 else 0.0,\n        \"entropy_mag\": entropy_like_from_magnetization_hist(mags),\n        \"n_meas\": int(len(mags)),\n    }\n    return out\n\n\ndef make_schedules(cfg: RunConfig) -> tuple[np.ndarray, np.ndarray]:\n    temps = np.linspace(cfg.temp_min, cfg.temp_max, cfg.temp_steps)\n    noises = np.linspace(cfg.noise_min, cfg.noise_max, cfg.noise_steps)\n    return temps, noises\n\n\ndef plot_heatmaps(cfg: RunConfig, results: list[dict], outdir: Path) -> None:\n    import matplotlib.pyplot as plt\n\n    temps, noises = make_schedules(cfg)\n    # reshape results into grids\n    shape = (len(noises), len(temps))\n    key_list = [\"m_abs_mean\", \"corr_nn_mean\", \"entropy_mag\"]\n    grids = {}\n    for k in key_list:\n        grids[k] = np.zeros(shape, dtype=float)\n\n    # index mapping\n    idx = {(r[\"noise\"], r[\"T\"]): r for r in results}\n    for ni, n in enumerate(noises):\n        for ti, t in enumerate(temps):\n            r = idx[(float(n), float(t))]\n            for k in key_list:\n                grids[k][ni, ti] = r[k]\n\n    def save_heatmap(key: str, title: str, cmap: str = \"viridis\") -> None:\n        fig, ax = plt.subplots(figsize=(7.2, 4.2))\n        im = ax.imshow(\n            grids[key],\n            origin=\"lower\",\n            aspect=\"auto\",\n            extent=[temps[0], temps[-1], noises[0], noises[-1]],\n            cmap=cmap,\n        )\n        ax.set_xlabel(\"Temperature T\")\n        ax.set_ylabel(\"Noise flip prob\")\n        ax.set_title(title)\n        fig.colorbar(im, ax=ax, shrink=0.9)\n        fig.tight_layout()\n        fig.savefig(outdir / f\"heatmap_{key}.png\", dpi=160)\n        plt.close(fig)\n\n    save_heatmap(\"m_abs_mean\", \"|m| mean\", cmap=\"magma\")\n    save_heatmap(\"corr_nn_mean\", \"Nearest-neighbor corr mean\", cmap=\"viridis\")\n    save_heatmap(\"entropy_mag\", \"Entropy(m) (hist)\", cmap=\"cividis\")\n\n    if cfg.show_plots:\n        # Optional: show last heatmap\n        import matplotlib.pyplot as plt  # noqa: F811\n\n        img = plt.imread(outdir / \"heatmap_m_abs_mean.png\")\n        plt.figure(figsize=(7, 4))\n        plt.imshow(img)\n        plt.axis(\"off\")\n        plt.show()\n\n\ndef main() -> None:\n    ap = argparse.ArgumentParser(description=\"Toy 2D Ising emergent classicality proxy experiment.\")\n    ap.add_argument(\"--l\", type=int, default=16)\n    ap.add_argument(\"--sweeps-per-step\", type=int, default=300)\n    ap.add_argument(\"--thermalization-sweeps\", type=int, default=200)\n    ap.add_argument(\"--measurement-every\", type=int, default=10)\n    ap.add_argument(\"--seed\", type=int, default=0)\n    ap.add_argument(\"--j\", type=float, default=1.0)\n    ap.add_argument(\"--h\", type=float, default=0.0)\n    ap.add_argument(\"--temp-min\", type=float, default=0.5)\n    ap.add_argument(\"--temp-max\", type=float, default=4.0)\n    ap.add_argument(\"--temp-steps\", type=int, default=13)\n    ap.add_argument(\"--noise-min\", type=float, default=0.0)\n    ap.add_argument(\"--noise-max\", type=float, default=0.6)\n    ap.add_argument(\"--noise-steps\", type=int, default=7)\n    ap.add_argument(\"--outdir\", type=str, default=\"out/toy_ising_emergent_classicality\")\n    ap.add_argument(\"--no-save-plots\", action=\"store_true\")\n    ap.add_argument(\"--show-plots\", action=\"store_true\")\n    ap.add_argument(\"--quiet\", action=\"store_true\")\n    args = ap.parse_args()\n\n    cfg = RunConfig(\n        l=args.l,\n        sweeps_per_step=args.sweeps_per_step,\n        thermalization_sweeps=args.thermalization_sweeps,\n        measurement_every=args.measurement_every,\n        seed=args.seed,\n        j=args.j,\n        h=args.h,\n        temp_min=args.temp_min,\n        temp_max=args.temp_max,\n        temp_steps=args.temp_steps,\n        noise_min=args.noise_min,\n        noise_max=args.noise_max,\n        noise_steps=args.noise_steps,\n        outdir=args.outdir,\n        save_plots=(not args.no_save_plots),\n        show_plots=args.show_plots,\n        verbose=(not args.quiet),\n    )\n\n    set_seeds(cfg.seed)\n    outdir = Path(\"/mnt/data\") / cfg.outdir\n    outdir.mkdir(parents=True, exist_ok=True)\n\n    temps, noises = make_schedules(cfg)\n    if cfg.verbose:\n        print(f\"Grid: {len(temps)} temps x {len(noises)} noises = {len(temps)*len(noises)} points\")\n        print(f\"Output: {outdir}\")\n\n    results: list[dict] = []\n    for n in noises:\n        for t in temps:\n            r = run_single_point(cfg, temp=float(t), noise=float(n))\n            results.append(r)\n            if cfg.verbose:\n                print(\n                    f\"T={r['T']:.3f} noise={r['noise']:.3f} |m|={r['m_abs_mean']:.3f} \"\n                    f\"corr={r['corr_nn_mean']:.3f} Hm={r['entropy_mag']:.3f}\"\n                )\n\n    # save json\n    meta = {\"config\": asdict(cfg), \"results\": results}\n    (outdir / \"results.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n\n    if cfg.save_plots:\n        plot_heatmaps(cfg, results, outdir)\n\n    if cfg.verbose:\n        print(\"Done.\")\n\n\nif __name__ == \"__main__\":\n    main()\n\"}\nDIR_STATE:[\"src/experiments/symbolic_rg_phi4.py\",\"src/experiments/toy_ising_emergent_classicality.py\"]"
        }
      ],
      "role": "assistant"
    }
  ],
  "codeResults": []
}