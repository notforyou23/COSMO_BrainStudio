{
  "content": "Implemented `src/core/robustness.py` to run robustness plans via compactification/flux scenario sampling (with optional Gaussian-copula correlations), stability metrics aggregation, finite-difference sensitivity analysis, and two stress tests (tail-scenario extremes and correlation shocks) in a backend-agnostic way driven by user-provided evaluation callables.",
  "reasoning": "",
  "responseId": "resp_047cde90faf4dd11006949a38d23b48195aa115ae7a493be24",
  "model": "gpt-5.2-2025-12-11",
  "usage": {
    "input_tokens": 4133,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 2556,
    "output_tokens_details": {
      "reasoning_tokens": 240
    },
    "total_tokens": 6689
  },
  "hadError": false,
  "errorType": null,
  "webSearchSources": [],
  "citations": [],
  "output": [
    {
      "id": "rs_047cde90faf4dd11006949a38dd2ac819591c176c463770d14",
      "type": "reasoning",
      "summary": []
    },
    {
      "id": "ci_047cde90faf4dd11006949a394c498819593fe8372c7ba4456",
      "type": "code_interpreter_call",
      "status": "completed",
      "code": "from pathlib import Path\nimport json, textwrap, os, numpy as np\ntarget_path = Path('/mnt/data').joinpath('src/core/robustness.py')\ntarget_path.parent.mkdir(parents=True, exist_ok=True)\n\nchunks = []\n\nchunks.append(\"\"\"\n\\\"\\\"\\\"Robustness utilities for hypothesis stability under compactification/flux uncertainty.\n\nThis module provides:\n- Scenario sampling (realistic compactification/flux choices via user-specified priors)\n- Local sensitivity analysis (finite-difference gradients)\n- Stress tests (tail scenarios and correlation shocks)\n\nThe module is deliberately backend-agnostic: users pass callables that map a scenario\n(dict-like parameters) to hypothesis evaluation results.\n\\\"\\\"\\\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom typing import Any, Callable, Dict, Iterable, List, Mapping, Optional, Sequence, Tuple\n\nimport numpy as np\n\n\nScenario = Dict[str, float]\nEvalResult = Dict[str, Any]\nEvaluateFn = Callable[[Scenario], EvalResult]\n\"\"\")\n\nchunks.append(\"\"\"\n@dataclass(frozen=True)\nclass ScenarioSampler:\n    \\\"\\\"\\\"Sampler for compactification/flux scenarios.\n\n    Parameters\n    ----------\n    base : baseline parameter point\n    priors : mapping param -> callable(rng) -> float, or (low, high) for uniform\n    corr : optional correlation matrix for a subset of keys (Gaussian copula).\n           Provide as (keys, matrix) where matrix is positive semidefinite.\n    \\\"\\\"\\\"\n\n    base: Scenario\n    priors: Mapping[str, Any]\n    corr: Optional[Tuple[Sequence[str], np.ndarray]] = None\n\n    def _draw_one(self, rng: np.random.Generator) -> Scenario:\n        s = dict(self.base)\n        for k, prior in self.priors.items():\n            if callable(prior):\n                s[k] = float(prior(rng))\n            else:\n                lo, hi = prior\n                s[k] = float(rng.uniform(lo, hi))\n        if self.corr is not None:\n            keys, mat = self.corr\n            z = rng.multivariate_normal(np.zeros(len(keys)), mat)\n            u = 0.5 * (1.0 + np.erf(z / np.sqrt(2.0)))  # normal CDF\n            for i, k in enumerate(keys):\n                prior = self.priors[k]\n                if callable(prior):\n                    # use inverse-CDF fallback: map u -> quantile via a small search\n                    s[k] = float(_quantile_from_sampler(prior, u[i], rng))\n                else:\n                    lo, hi = prior\n                    s[k] = float(lo + (hi - lo) * u[i])\n        return s\n\n    def sample(self, n: int, seed: Optional[int] = None) -> List[Scenario]:\n        rng = np.random.default_rng(seed)\n        return [self._draw_one(rng) for _ in range(int(n))]\n\"\"\")\n\nchunks.append(\"\"\"\ndef _quantile_from_sampler(prior: Callable[[np.random.Generator], float], q: float,\n                           rng: np.random.Generator, m: int = 2048) -> float:\n    \\\"\\\"\\\"Approximate inverse-CDF for an arbitrary sampler prior using Monte Carlo.\\\"\\\"\\\"\n    xs = np.array([prior(rng) for _ in range(m)], dtype=float)\n    xs.sort()\n    idx = int(np.clip(q, 0.0, 1.0) * (m - 1))\n    return float(xs[idx])\n\n\ndef evaluate_scenarios(evaluate: EvaluateFn, scenarios: Iterable[Scenario]) -> List[EvalResult]:\n    \\\"\\\"\\\"Evaluate a hypothesis/model function on many scenarios.\\\"\\\"\\\"\n    return [evaluate(dict(s)) for s in scenarios]\n\"\"\")\n\nchunks.append(\"\"\"\ndef stability_metrics(results: Sequence[EvalResult],\n                      pass_key: str = \"pass\",\n                      signature_key: str = \"signature\") -> Dict[str, Any]:\n    \\\"\\\"\\\"Summarize stability across scenarios.\n\n    Expected EvalResult fields:\n      - pass_key: bool, conjecture+consistency satisfied\n      - signature_key: scalar (or array-like) observable signature value(s)\n    \\\"\\\"\\\"\n    if not results:\n        return {\"n\": 0, \"pass_rate\": np.nan, \"signature_mean\": None, \"signature_std\": None}\n\n    passes = np.array([bool(r.get(pass_key, False)) for r in results])\n    sigs = [r.get(signature_key, np.nan) for r in results]\n    sigs = np.array(sigs, dtype=float) if np.isscalar(sigs[0]) else np.array(sigs, dtype=float)\n\n    out: Dict[str, Any] = {\"n\": len(results), \"pass_rate\": float(passes.mean())}\n    out[\"signature_mean\"] = np.nanmean(sigs, axis=0).tolist() if sigs.ndim > 0 else float(np.nanmean(sigs))\n    out[\"signature_std\"] = np.nanstd(sigs, axis=0).tolist() if sigs.ndim > 0 else float(np.nanstd(sigs))\n    return out\n\"\"\")\n\nchunks.append(\"\"\"\ndef finite_diff_sensitivity(evaluate: EvaluateFn,\n                            scenario: Scenario,\n                            keys: Sequence[str],\n                            rel_step: float = 1e-2,\n                            signature_key: str = \"signature\") -> Dict[str, float]:\n    \\\"\\\"\\\"Central finite-difference sensitivity of the signature wrt selected parameters.\\\"\\\"\\\"\n    base = dict(scenario)\n    y0 = evaluate(base).get(signature_key, np.nan)\n    if not np.isscalar(y0):\n        y0 = float(np.asarray(y0).ravel()[0])\n\n    sens: Dict[str, float] = {}\n    for k in keys:\n        x = float(base.get(k, 0.0))\n        h = rel_step * (abs(x) + 1.0)\n        up, dn = dict(base), dict(base)\n        up[k], dn[k] = x + h, x - h\n        yu = evaluate(up).get(signature_key, np.nan)\n        yd = evaluate(dn).get(signature_key, np.nan)\n        yu = float(np.asarray(yu).ravel()[0]) if not np.isscalar(yu) else float(yu)\n        yd = float(np.asarray(yd).ravel()[0]) if not np.isscalar(yd) else float(yd)\n        sens[k] = float((yu - yd) / (2.0 * h))\n    sens[\"_baseline_signature\"] = float(y0)\n    return sens\n\"\"\")\n\nchunks.append(\"\"\"\ndef stress_test_tail_scenarios(sampler: ScenarioSampler,\n                               evaluate: EvaluateFn,\n                               n: int = 256,\n                               tail_q: float = 0.98,\n                               seed: Optional[int] = None,\n                               signature_key: str = \"signature\") -> Dict[str, Any]:\n    \\\"\\\"\\\"Stress test using tail draws: keep scenarios with extreme signatures.\\\"\\\"\\\"\n    rng = np.random.default_rng(seed)\n    scenarios = sampler.sample(int(n), seed=int(rng.integers(0, 2**32 - 1)))\n    results = evaluate_scenarios(evaluate, scenarios)\n    sig = np.array([r.get(signature_key, np.nan) for r in results], dtype=float)\n    hi = np.nanquantile(sig, tail_q)\n    lo = np.nanquantile(sig, 1.0 - tail_q)\n    idx = np.where((sig >= hi) | (sig <= lo))[0]\n    tail_results = [results[i] for i in idx.tolist()]\n    return {\"n_total\": len(results), \"n_tail\": len(tail_results), \"tail_metrics\": stability_metrics(tail_results)}\n\"\"\")\n\nchunks.append(\"\"\"\ndef stress_test_correlation_shock(sampler: ScenarioSampler,\n                                  evaluate: EvaluateFn,\n                                  shock: float = 0.2,\n                                  n: int = 512,\n                                  seed: Optional[int] = None) -> Dict[str, Any]:\n    \\\"\\\"\\\"Stress test by perturbing the sampler's correlation matrix (if present).\\\"\\\"\\\"\n    if sampler.corr is None:\n        res = evaluate_scenarios(evaluate, sampler.sample(n, seed=seed))\n        return {\"applied\": False, \"metrics\": stability_metrics(res)}\n\n    keys, mat = sampler.corr\n    rng = np.random.default_rng(seed)\n    noise = rng.normal(scale=shock, size=mat.shape)\n    mat2 = mat + 0.5 * (noise + noise.T)\n    # project to PSD by clipping eigenvalues\n    w, v = np.linalg.eigh(mat2)\n    w = np.clip(w, 1e-8, None)\n    mat2 = (v * w) @ v.T\n    s2 = ScenarioSampler(base=sampler.base, priors=sampler.priors, corr=(list(keys), mat2))\n    res = evaluate_scenarios(evaluate, s2.sample(n, seed=int(rng.integers(0, 2**32 - 1))))\n    return {\"applied\": True, \"shock\": float(shock), \"metrics\": stability_metrics(res)}\n\"\"\")\n\nchunks.append(\"\"\"\ndef run_robustness_plan(evaluate: EvaluateFn,\n                        sampler: ScenarioSampler,\n                        n: int = 2048,\n                        sensitivity_keys: Optional[Sequence[str]] = None,\n                        seed: Optional[int] = None) -> Dict[str, Any]:\n    \\\"\\\"\\\"End-to-end robustness plan: sampling, metrics, sensitivity, stress tests.\\\"\\\"\\\"\n    scenarios = sampler.sample(int(n), seed=seed)\n    results = evaluate_scenarios(evaluate, scenarios)\n    report: Dict[str, Any] = {\"metrics\": stability_metrics(results), \"n\": int(n)}\n\n    if sensitivity_keys:\n        report[\"sensitivity\"] = finite_diff_sensitivity(evaluate, sampler.base, list(sensitivity_keys))\n\n    report[\"stress_tail\"] = stress_test_tail_scenarios(sampler, evaluate, n=max(128, n // 8), seed=seed)\n    report[\"stress_corr\"] = stress_test_correlation_shock(sampler, evaluate, n=max(256, n // 4), seed=seed)\n    return report\n\"\"\")\n\nfinal_text = '\\n'.join(block.strip('\\n') for block in chunks).strip() + '\\n'\ntarget_path.write_text(final_text, encoding='utf-8')\n\nprint('FILE_WRITTEN:src/core/robustness.py')\nprint('DIR_STATE:' + json.dumps(sorted(str(p.relative_to(Path(\"/mnt/data\"))) for p in target_path.parent.glob('*') if p.is_file())))\n",
      "container_id": "cntr_6949a1d497e081909a00da1af070d618029e616ce667a0de",
      "outputs": [
        {
          "type": "logs",
          "logs": "FILE_WRITTEN:src/core/robustness.py\nDIR_STATE:[\"src/core/conjectures.py\", \"src/core/holography.py\", \"src/core/models.py\", \"src/core/observables.py\", \"src/core/robustness.py\"]\n"
        }
      ]
    },
    {
      "id": "msg_047cde90faf4dd11006949a3c12e748195aa94b85a3d848c25",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "annotations": [],
          "logprobs": [],
          "text": "Implemented `src/core/robustness.py` to run robustness plans via compactification/flux scenario sampling (with optional Gaussian-copula correlations), stability metrics aggregation, finite-difference sensitivity analysis, and two stress tests (tail-scenario extremes and correlation shocks) in a backend-agnostic way driven by user-provided evaluation callables."
        }
      ],
      "role": "assistant"
    }
  ],
  "codeResults": []
}