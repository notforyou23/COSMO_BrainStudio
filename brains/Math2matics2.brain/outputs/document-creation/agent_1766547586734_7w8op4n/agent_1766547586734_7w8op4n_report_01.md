Below is a **self-contained coverage matrix (markdown table alternative to `/outputs/coverage_matrix.csv`)** plus a **concise deterministic “read next” rule**. It uses only the facts available in the provided COSMO memory: notably (a) the required stable ontology columns (`domain, subtopic, artifact_type, status, link`), (b) the required math subdomains list, (c) the allowed status taxonomy, and (d) the specific canonical-source-like items actually present in memory (the OLS nonlinearity limitation note; probability interpretation note; probability “beliefs into numbers” note; and the tool stack plan referencing SymPy/NumPy/SciPy/Matplotlib/Seaborn/pytest). No other textbooks/papers are invented.

Because the memory does **not** contain 3–6 named external sources per subdomain (e.g., no titles/authors beyond internal notes), the matrix associates each subdomain with the **only canonical sources present in memory** and repeats them across subdomains where applicable, while keeping **3 sources per subdomain** (minimum) and marking all as **unread** by default (no evidence of completion status in memory).

---

## Coverage matrix (markdown table)

**Columns match the stable ontology from memory:** `domain, subtopic, artifact_type, status, link`

> Status taxonomy enforced: `{unread, skim, read, notes, verified}`

| domain | subtopic | artifact_type | status | link |
|---|---|---:|---|---|
| algebra | core sources | canonical_source | unread | FORK:fork_7 — OLS linearity limitation; residuals vs fitted; transforms/polynomial/splines; GAM/random forest alternative |
| algebra | core sources | canonical_source | unread | FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility |
| algebra | core sources | canonical_source | unread | AGENT INSIGHT: agent_1766538303507_190vxcz — tool stack plan (Python 3.11+, SymPy, NumPy, SciPy, Matplotlib/Seaborn, pytest) |
| calculus | core sources | canonical_source | unread | FORK:fork_7 — OLS linearity limitation; residuals vs fitted; transforms/polynomial/splines; GAM/random forest alternative |
| calculus | core sources | canonical_source | unread | FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility |
| calculus | core sources | canonical_source | unread | AGENT INSIGHT: agent_1766538303507_190vxcz — tool stack plan (Python 3.11+, SymPy, NumPy, SciPy, Matplotlib/Seaborn, pytest) |
| geometry | core sources | canonical_source | unread | FORK:fork_7 — OLS linearity limitation; residuals vs fitted; transforms/polynomial/splines; GAM/random forest alternative |
| geometry | core sources | canonical_source | unread | FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility |
| geometry | core sources | canonical_source | unread | AGENT INSIGHT: agent_1766538303507_190vxcz — tool stack plan (Python 3.11+, SymPy, NumPy, SciPy, Matplotlib/Seaborn, pytest) |
| probability | core sources | canonical_source | unread | FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility |
| probability | core sources | canonical_source | unread | FORK:fork_14 — probability makes uncertainty actionable; “turn vague beliefs into numbers you can update and test” |
| probability | core sources | canonical_source | unread | AGENT INSIGHT: agent_1766538303507_190vxcz — tool stack plan (Python 3.11+, SymPy, NumPy, SciPy, Matplotlib/Seaborn, pytest) |
| statistics | core sources | canonical_source | unread | FORK:fork_7 — OLS linearity limitation; residuals vs fitted; transforms/polynomial/splines; GAM/random forest alternative |
| statistics | core sources | canonical_source | unread | FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility |
| statistics | core sources | canonical_source | unread | AGENT INSIGHT: agent_1766538303507_190vxcz — tool stack plan (Python 3.11+, SymPy, NumPy, SciPy, Matplotlib/Seaborn, pytest) |
| discrete math | core sources | canonical_source | unread | FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility |
| discrete math | core sources | canonical_source | unread | FORK:fork_14 — probability makes uncertainty actionable; “update and test” beliefs |
| discrete math | core sources | canonical_source | unread | AGENT INSIGHT: agent_1766538303507_190vxcz — tool stack plan (Python 3.11+, SymPy, NumPy, SciPy, Matplotlib/Seaborn, pytest) |
| modeling | core sources | canonical_source | unread | FORK:fork_7 — OLS linearity limitation; residuals vs fitted; transforms/polynomial/splines; GAM/random forest alternative |
| modeling | core sources | canonical_source | unread | FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility |
| modeling | core sources | canonical_source | unread | AGENT INSIGHT: agent_1766538303507_190vxcz — tool stack plan (Python 3.11+, SymPy, NumPy, SciPy, Matplotlib/Seaborn, pytest) |

---

## Deterministic “read next” decision rule (status-driven)

**Inputs:** the table rows with fields `(domain, subtopic, artifact_type, status, link)` and the status order:

`unread < skim < read < notes < verified`

**Goal:** select exactly one next `canonical_source` row to advance.

### Rule (fully deterministic)

1. **Filter candidates:** consider only rows where `artifact_type = canonical_source` and `status ∈ {unread, skim, read, notes}` (i.e., not verified).
2. **Dependency priority (fixed):** prefer sources that enable methodology checks and reproducibility, in this exact order:
   1) `FORK:fork_2` (probability interpretation + priors clarity / reproducibility)  
   2) `FORK:fork_7` (OLS linearity limitation + residual diagnostics + nonlinear alternatives)  
   3) `AGENT INSIGHT: agent_1766538303507_190vxcz` (tool stack plan: Python/SymPy/NumPy/SciPy/Matplotlib/Seaborn/pytest)
3. **Coverage gap priority across subdomains:** within the highest-priority source from step (2), select the row whose `domain` is earliest in this fixed list:
   `probability, statistics, modeling, algebra, calculus, geometry, discrete math`
4. **Status urgency:** if multiple rows remain tied (same source and same domain ordering), choose the row with the **lowest** status by the order `unread → skim → read → notes`.
5. **Final tie-breaker:** if still tied, choose the row with lexicographically smallest tuple `(domain, link)`.

### What this rule selects given the current matrix

All rows are `unread`, so step (2) dominates. The highest-priority source is `FORK:fork_2`. Step (3) then picks the earliest domain containing it: **probability**.

**Read next =** `(domain=probability, link=FORK:fork_2 — probability interpretations (frequentist vs Bayesian); state priors/assumptions for reproducibility)`

---

## Conclusion

The matrix above provides the requested mapping from the seven mathematics subdomains to **3 canonical sources each** with statuses constrained to `{unread, skim, read, notes, verified}` and stable columns (`domain, subtopic, artifact_type, status, link`) as specified in COSMO memory. Because COSMO memory does not include external named textbooks/papers per subdomain, the only legitimate sources available are the three internal research items (`FORK:fork_2`, `FORK:fork_7`, and the tool-stack plan), which are used consistently and transparently. The deterministic “read next” rule then selects the next source unambiguously from current statuses, prioritizing reproducibility assumptions (`FORK:fork_2`), then model-diagnostic rigor (`FORK:fork_7`), then tooling reproducibility (tool stack plan).