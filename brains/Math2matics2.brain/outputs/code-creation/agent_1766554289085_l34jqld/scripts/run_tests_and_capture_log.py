#!/usr/bin/env python3
from __future__ import annotations

import argparse, os, sys, shlex, json, subprocess
from pathlib import Path
from datetime import datetime, timezone

ROOT = Path(__file__).resolve().parents[1]
OUT_DIR = ROOT / "outputs"
LOG_DIR = OUT_DIR / "logs"
INDEX_MD = OUT_DIR / "index.md"
RUN_STAMP = OUT_DIR / "run_stamp.json"

RESULT_EXTS = {".json", ".csv", ".parquet", ".png", ".md", ".txt", ".html"}
EXCLUDE_DIRS = {"logs", ".git", "__pycache__", ".pytest_cache", ".mypy_cache", ".ruff_cache"}

def utc_ts() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H-%M-%S-%fZ")

def rel(p: Path) -> str:
    return p.relative_to(ROOT).as_posix()

def ensure_dirs() -> None:
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    OUT_DIR.mkdir(parents=True, exist_ok=True)

def run_and_capture(cmd: list[str], log_path: Path) -> int:
    with log_path.open("w", encoding="utf-8") as f:
        f.write(f"# cmd: {shlex.join(cmd)}\n# cwd: {ROOT.as_posix()}\n\n")
        f.flush()
        p = subprocess.Popen(cmd, cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)
        assert p.stdout is not None
        for line in p.stdout:
            f.write(line)
            f.flush()
            sys.stdout.write(line)
            sys.stdout.flush()
        return p.wait()

def discover_artifacts() -> list[str]:
    paths: list[Path] = []
    for p in OUT_DIR.rglob("*"):
        if not p.is_file():
            continue
        parts = set(p.relative_to(OUT_DIR).parts)
        if parts & EXCLUDE_DIRS:
            continue
        if p.name == INDEX_MD.name:
            continue
        if p.suffix.lower() in RESULT_EXTS or p.name == "run_stamp.json":
            paths.append(p)
    paths = sorted(set(paths), key=lambda x: rel(x))
    return [rel(p) for p in paths]

def list_logs() -> list[str]:
    if not LOG_DIR.exists():
        return []
    logs = sorted((p for p in LOG_DIR.glob("*.log") if p.is_file()), key=lambda p: p.name, reverse=True)
    return [rel(p) for p in logs]

def write_index(logs: list[str], artifacts: list[str]) -> None:
    lines = []
    lines += ["# Outputs index", ""]
    lines += ["This file is auto-generated by `scripts/run_tests_and_capture_log.py`.", ""]
    lines += ["## Logs (newest first)", ""]
    for lp in logs:
        lines.append(f"- [{lp}]({lp})")
    if not logs:
        lines.append("- (none)")
    lines += ["", "## Artifacts", ""]
    for ap in artifacts:
        lines.append(f"- [{ap}]({ap})")
    if not artifacts:
        lines.append("- (none)")
    lines.append("")
    INDEX_MD.parent.mkdir(parents=True, exist_ok=True)
    INDEX_MD.write_text("\n".join(lines), encoding="utf-8")

def main() -> int:
    ap = argparse.ArgumentParser(description="Run tests, capture log, write run_stamp.json, and update outputs/index.md.")
    ap.add_argument("--cmd", default=os.environ.get("TEST_CMD", "python -m pytest -q"),
                    help="Test command to run (default: env TEST_CMD or 'python -m pytest -q').")
    args = ap.parse_args()

    ensure_dirs()
    ts = utc_ts()
    log_path = LOG_DIR / f"{ts}_tests.log"
    cmd = shlex.split(args.cmd)

    start = datetime.now(timezone.utc).isoformat()
    rc = run_and_capture(cmd, log_path)
    end = datetime.now(timezone.utc).isoformat()

    stamp = {
        "kind": "tests",
        "timestamp": ts,
        "start_time": start,
        "end_time": end,
        "cwd": str(ROOT),
        "cmd": cmd,
        "returncode": rc,
        "log_path": rel(log_path),
    }
    RUN_STAMP.write_text(json.dumps(stamp, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    logs = list_logs()
    artifacts = discover_artifacts()
    if rel(RUN_STAMP) not in artifacts:
        artifacts.append(rel(RUN_STAMP))
        artifacts = sorted(set(artifacts))
    write_index(logs, artifacts)
    return rc

if __name__ == "__main__":
    raise SystemExit(main())
