You are inside the OpenAI code interpreter environment with filesystem access to /mnt/data.

Mission summary: Fix the syntax error, add a deterministic seed and fixed output filenames (e.g., ./outputs/toy_experiment/results.json), wire it into the single entrypoint script, and add a pytest that runs the function/module and validates the produced artifact schema.
Project: generated_library_1766554101798 (json library)

Target file details:
- Path: src/toy_experiment/results_schema.py
- Purpose: Defines the results artifact schema and provides a pure-Python validator used by both runtime and tests.
- Category: source

Other planned files (for context only):
- src/toy_experiment/__init__.py: Package initializer exposing the public API for running the toy experiment and producing a results artifact.
- src/toy_experiment/run.py: Implements the deterministic toy experiment (fixed seed) and writes results to the fixed output path outputs/toy_experiment/results.json.
- src/main.py: Single project entrypoint script wiring CLI invocation to the toy experiment runner and ensuring deterministic, fixed-filename output.
- tests/test_results_schema_validation.py: Pytest that runs the entrypoint/module, asserts the fixed output file is produced, and validates the JSON artifact against the expected schema.

Reference insights:
- [INTROSPECTION] 2025-12-24T03-39-48-670Z_tests_test_results_schema_validation_py_stage1_attempt1_prompt.txt from code-creation agent agent_1
- [AGENT INSIGHT: agent_1766550864729_p9ds97q] Invest in infrastructure lemmas: compactness/tightness, decomposition (structured+pseudorandom)
- [AGENT: agent_1766541933970_kpux1wi] {"agentId":"agent_1766541933970_kpux1wi","goalId":"goal_18","containerId":"cntr_694b4a714b208190ab6f0ee
- [AGENT: agent_1766550864729_p9ds97q] Across the implications-and-consequences, systems-thinking, and psychological perspectives, the dominan
- [AGENT INSIGHT: agent_1766550864729_t9or71v] Assumptions are design variables and integration dependencies: they must be explicitly chosen, 

Stage details:
- Stage: Stage 1
- Mode: create
- Goal: Defines the results artifact schema and provides a pure-Python validator used by both runtime and tests.
- Line budget for this stage: <= 150 new/changed lines.

Implementation tasks (execute using Python in this environment):
1. from pathlib import Path
2. import json
3. target_path = Path('/mnt/data').joinpath('src/toy_experiment/results_schema.py')
4. target_path.parent.mkdir(parents=True, exist_ok=True)
5. Build the entire stage deliverable (<= 150 lines) as a list named chunks where each item is a multiline string representing a contiguous block of code without leading or trailing blank lines.
6. final_text = '\n'.join(block.strip('\n') for block in chunks).strip() + '\n'
7. target_path.write_text(final_text, encoding='utf-8')
8. print('FILE_WRITTEN:src/toy_experiment/results_schema.py')
9. print('DIR_STATE:' + json.dumps(sorted(str(p.relative_to(Path("/mnt/data"))) for p in target_path.parent.glob('*') if p.is_file())))

Constraints:
- Ensure the new file fully satisfies the stage goal with no placeholders or TODO markers.
- Keep the newly written code within the stated line/character budget.
- Keep console output short (only FILE_WRITTEN / DIR_STATE plus essential status).
- Do not touch files outside src/toy_experiment/results_schema.py.
- After writing the file, provide a one-sentence summary. Do not list the file contents in the final message.
