# Research Summary

**Agent:** agent_1766881291301_fyxhu15
**Mission:** QA found borderline confidence - research agent should verify claims
**Completed:** 2025-12-28T00:24:12.260Z

## Summary

Across 2010–2024, there is no single, field-wide meta-analytic “replication rate” for all biomedical research that can be stated defensibly. The most informative evidence comes from (1) targeted replication initiatives in specific areas (notably preclinical cancer biology) and (2) meta-research identifying structural drivers of non-replication. Early, influential reports from industry and prominent commentators (e.g., Bayer’s internal assessments and Begley & Ellis 2012) suggested low reproducibility in parts of preclinical research, but these were not fully transparent, multi-lab replication studies and should be treated as indicative rather than definitive.

The strongest prospective, structured evidence cited here is the Reproducibility Project: Cancer Biology (RP:CB, eLife, 2021), which found substantial effect-size shrinkage on replication and mixed “success” depending on the criteria used—highlighting that binary replication definitions (p<0.05 vs not) can be misleading. In parallel, the most consistently supported explanatory factors for failed replications are low power/small samples, selective reporting/publication bias, and analytic flexibility (p-hacking). Registered Reports (RRs) are best supported as a process change that reduces selective reporting and shifts the literature toward more null results; however, a generalized “RR replication success rate” across fields remains insufficiently established, and at least one high-profile claim of very high replication under preregistered/high-power practices has been complicated by a 2024 retraction—so conclusions must be cautious and evidence-weighted.

Actionable implication: treat replication as domain- and design-dependent; prioritize higher power, preregistration/Registered Reports where feasible, and rigorous transparency (materials/data/code) because practical barriers (incomplete methods, unavailable data/materials) can prevent replication attempts from being executed at all—independently of whether the underlying effect is real.

## Key Findings

1. Prospective preclinical replication evidence (RP: Cancer Biology, eLife 2021): 50 replication experiments from 23 papers assessed 158 effects; replication effect sizes were ~85% smaller on average than originals, and ~46% (51/112) of eligible effects were judged to have “succeeded on more criteria than they failed” under the project’s multi-criterion evaluation framework.

2. Influential but non-prospective/less-transparent preclinical indicators reported very low confirmation rates (e.g., Begley & Ellis 2012 reported ~11% confirmation of 53 ‘landmark’ preclinical cancer studies; Bayer internal replication concerns often summarized as ~21–25%). These figures are widely cited but should be treated as suggestive because protocols, selection, and criteria were not fully standardized or publicly auditable like later replication projects.

3. Clinical replicability estimates are harder to generalize: a 2024 analysis of highly cited clinical studies found 24/89 had “valid replications,” and within that selective subset replicability was estimated at ~83% (20/24), explicitly cautioned as potentially non-generalizable beyond the subset with available/qualifying replications.

4. Most consistently supported drivers of non-replication: (a) low statistical power/small samples (which inflate published effect sizes when significant), (b) selective reporting/publication bias (including bias at the write-up/submission stage), and (c) analytic flexibility/p-hacking, which can increase false-positive rates well above nominal levels.

5. Registered Reports (2020–2024): evidence most strongly supports that RRs change the result distribution (more nulls/fewer ‘positive’ findings; e.g., one psychology comparison reported ~44% positives in RRs vs ~96% in standard reports for first hypotheses), but a stable, field-wide RR ‘replication success rate’ is not yet well established; moreover, one prominent high-replication claim under preregistered/high-power practices was later retracted in 2024, further reinforcing the need for cautious interpretation.

## Research Queries

1. replication rate biomedical research 2010-2024 meta-analysis
2. common causes failed replications p-hacking small samples
3. registered reports replication success rates 2020-2024

## Sources

Total sources consulted: 119

See `bibliography.bib` for citation-ready BibTeX entries.
