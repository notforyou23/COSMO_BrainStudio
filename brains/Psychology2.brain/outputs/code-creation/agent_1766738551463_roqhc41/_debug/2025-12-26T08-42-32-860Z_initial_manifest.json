{
  "manifestVersion": "2.0.0-plan",
  "agentId": "agent_1766738551463_roqhc41",
  "agentType": "code-creation",
  "goalId": "goal_134",
  "missionId": "strategic_goal_134_1766738551463",
  "spawnCycle": 147,
  "coordinatorReview": null,
  "spawnedBy": "strategic_spawner",
  "triggerSource": "strategic_goal",
  "spawningReason": "high",
  "createdAt": "2025-12-26T08:42:44.262Z",
  "completedAt": null,
  "canonical": false,
  "supersedes": [],
  "supersededBy": null,
  "deliverableType": "code",
  "files": [
    {
      "path": "src/api_server.py",
      "description": "Implements a runnable Python API server with an end-to-end DOI run endpoint that loads a fixed DOI test set, resolves sources/metadata per DOI, and writes runtime/_build/tables/doi_results.csv and runtime/_build/reports/doi_run_report.json with explicit per-DOI success/failure reasons.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:42:44.262Z"
    },
    {
      "path": "src/doi_pipeline.py",
      "description": "Provides the DOI resolution orchestration pipeline that validates/normalizes DOIs, queries provider resolvers in order, aggregates metadata, and returns structured per-DOI results with explicit failure categories and reasons.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:42:44.262Z"
    },
    {
      "path": "src/doi_providers.py",
      "description": "Defines provider client implementations (e.g., Crossref and DataCite) with robust HTTP handling, timeouts, rate-limit/backoff behavior, and consistent error mapping for the pipeline.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:42:44.262Z"
    },
    {
      "path": "src/exporters.py",
      "description": "Contains exporters that take pipeline results and deterministically write doi_results.csv and doi_run_report.json into runtime/_build with schema/versioning and explicit success/failure summaries.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:42:44.262Z"
    },
    {
      "path": "src/doi_test_set.py",
      "description": "Stores the small fixed DOI test set (as a Python constant with per-DOI provenance/notes and expected resolvability flags) used by api_server.py for the end-to-end run.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:42:44.262Z"
    },
    {
      "path": "docs/doi_test_set_and_provenance.md",
      "description": "Documents the chosen fixed DOI test set, provenance/selection criteria, and interpretation of success/failure reasons produced in the report and CSV outputs.",
      "category": "documentation",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:42:44.262Z"
    },
    {
      "path": "config/doi_run_config.json",
      "description": "Provides configurable runtime settings for the DOI run (provider order, timeouts, user agent/contact, output paths, and retry limits) used by api_server.py and the pipeline.",
      "category": "config",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:42:44.262Z"
    }
  ],
  "integrationStatus": "pending",
  "reviewNotes": null,
  "missionDescription": "Create a small fixed DOI test set, run api_server.py end-to-end to resolve sources/metadata, and save results to runtime/_build/tables/doi_results.csv and runtime/_build/reports/doi_run_report.json with explicit success/failure reasons per DOI.",
  "missionSuccessCriteria": [
    "Complete strategic task identified by Meta-Coordinator or escalated by Strategic Tracker",
    "Curated insight (actionability 8-9/10): Turns the citation/primary-source access MVP into an executable, testable component by running an end-to-end DOI list and saving machine-readable outputsâ€”directly supporting primary-source provenance ..."
  ],
  "projectName": "small fixed DOI test set, run api_server.py end-to-end to resolve sources/metadata, and save results to runtime/_build/tables/doi_results.csv and runtime/_build/reports/doi_run_report.json with explicit success/failure reasons per DOI.",
  "language": "python",
  "type": "api_server",
  "status": "in_progress",
  "requirements": [],
  "lastSavedAt": "2025-12-26T08:42:44.263Z"
}