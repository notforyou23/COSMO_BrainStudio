{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Meta-analysis demo (toy dataset)\n",
        "\n",
        "This notebook creates/loads a tiny CSV, computes fixed- and random-effects pooled estimates (inverse-variance, DerSimonian–Laird), saves a forest plot and summary table into `outputs/`, and appends a run log with timestamps and file paths.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BASE = Path('/Users/jtr/_JTR23_/COSMO/runtime/outputs/execution')\n",
        "DATA_DIR = BASE / 'data'\n",
        "OUT_DIR = BASE / 'outputs'\n",
        "for d in (DATA_DIR, OUT_DIR):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "csv_path = DATA_DIR / 'toy_extraction.csv'\n",
        "\n",
        "# Toy dataset: log(OR) with standard error (5–10 rows)\n",
        "if not csv_path.exists():\n",
        "    toy = pd.DataFrame({\n",
        "        'study': ['Study A', 'Study B', 'Study C', 'Study D', 'Study E', 'Study F', 'Study G'],\n",
        "        'yi':    [-0.20,     0.10,      -0.05,     0.30,      -0.15,     0.05,      0.25],\n",
        "        'sei':   [0.15,      0.20,      0.18,      0.25,      0.16,      0.22,      0.19],\n",
        "        'year':  [2015,      2016,      2017,      2018,      2019,      2020,      2021],\n",
        "    })\n",
        "    toy.to_csv(csv_path, index=False)\n",
        "\n",
        "csv_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "required = {'study','yi','sei'}\n",
        "missing = required - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f'Missing columns in CSV: {sorted(missing)}')\n",
        "\n",
        "df = df.copy()\n",
        "df['vi'] = df['sei'] ** 2\n",
        "df['w_fe'] = 1.0 / df['vi']\n",
        "df['ci_lo'] = df['yi'] - 1.96 * df['sei']\n",
        "df['ci_hi'] = df['yi'] + 1.96 * df['sei']\n",
        "\n",
        "def pooled_fixed(yi, vi):\n",
        "    w = 1.0 / vi\n",
        "    mu = np.sum(w * yi) / np.sum(w)\n",
        "    se = np.sqrt(1.0 / np.sum(w))\n",
        "    return mu, se\n",
        "\n",
        "def heterogeneity_Q(yi, vi, mu_fe=None):\n",
        "    if mu_fe is None:\n",
        "        mu_fe, _ = pooled_fixed(yi, vi)\n",
        "    w = 1.0 / vi\n",
        "    Q = np.sum(w * (yi - mu_fe) ** 2)\n",
        "    df_q = max(int(len(yi) - 1), 0)\n",
        "    return Q, df_q\n",
        "\n",
        "def tau2_dl(yi, vi):\n",
        "    mu_fe, _ = pooled_fixed(yi, vi)\n",
        "    Q, df_q = heterogeneity_Q(yi, vi, mu_fe)\n",
        "    w = 1.0 / vi\n",
        "    c = np.sum(w) - (np.sum(w**2) / np.sum(w))\n",
        "    tau2 = max(0.0, (Q - df_q) / c) if c > 0 else 0.0\n",
        "    return tau2, Q, df_q\n",
        "\n",
        "def pooled_random(yi, vi):\n",
        "    tau2, Q, df_q = tau2_dl(yi, vi)\n",
        "    w = 1.0 / (vi + tau2)\n",
        "    mu = np.sum(w * yi) / np.sum(w)\n",
        "    se = np.sqrt(1.0 / np.sum(w))\n",
        "    return mu, se, tau2, Q, df_q\n",
        "\n",
        "yi = df['yi'].to_numpy(float)\n",
        "vi = df['vi'].to_numpy(float)\n",
        "\n",
        "mu_fe, se_fe = pooled_fixed(yi, vi)\n",
        "mu_re, se_re, tau2, Q, df_q = pooled_random(yi, vi)\n",
        "I2 = max(0.0, (Q - df_q) / Q) * 100.0 if Q > 0 else 0.0\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    {'model':'fixed',  'k': len(df), 'mu': mu_fe, 'se': se_fe, 'ci_lo': mu_fe-1.96*se_fe, 'ci_hi': mu_fe+1.96*se_fe, 'tau2': 0.0,  'Q': Q, 'df': df_q, 'I2_pct': I2},\n",
        "    {'model':'random', 'k': len(df), 'mu': mu_re, 'se': se_re, 'ci_lo': mu_re-1.96*se_re, 'ci_hi': mu_re+1.96*se_re, 'tau2': tau2, 'Q': Q, 'df': df_q, 'I2_pct': I2},\n",
        "])\n",
        "\n",
        "df.head(), summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save summary table\n",
        "summary_path = OUT_DIR / 'meta_summary.csv'\n",
        "summary.to_csv(summary_path, index=False)\n",
        "\n",
        "# Forest plot (log scale metric; also show exponentiated OR on right axis labels)\n",
        "k = len(df)\n",
        "ypos = np.arange(k, 0, -1)\n",
        "\n",
        "fig_h = 0.55 * k + 2.8\n",
        "fig, ax = plt.subplots(figsize=(8.8, fig_h))\n",
        "\n",
        "# Study CIs\n",
        "ax.hlines(ypos, df['ci_lo'], df['ci_hi'], color='black', lw=1)\n",
        "sizes = 60 * (df['w_fe'] / df['w_fe'].max())\n",
        "ax.scatter(df['yi'], ypos, s=sizes, color='black', zorder=3)\n",
        "\n",
        "# Reference line at 0\n",
        "ax.axvline(0.0, color='gray', lw=1, linestyle='--')\n",
        "\n",
        "# Pooled effects (diamonds)\n",
        "def diamond(ax, mu, lo, hi, y, height=0.25, **kwargs):\n",
        "    xs = [lo, mu, hi, mu, lo]\n",
        "    ys = [y,  y+height, y, y-height, y]\n",
        "    ax.plot(xs, ys, **kwargs)\n",
        "\n",
        "y_fe = 0.1\n",
        "y_re = -0.6\n",
        "diamond(ax, mu_fe, mu_fe-1.96*se_fe, mu_fe+1.96*se_fe, y_fe, color='tab:blue', lw=2)\n",
        "diamond(ax, mu_re, mu_re-1.96*se_re, mu_re+1.96*se_re, y_re, color='tab:red', lw=2)\n",
        "\n",
        "# Labels\n",
        "ax.set_yticks(list(ypos) + [y_fe, y_re])\n",
        "ax.set_yticklabels(list(df['study']) + ['Pooled (FE)', 'Pooled (RE)'])\n",
        "ax.set_xlabel('Effect size (log OR)')\n",
        "\n",
        "x_all = np.r_[df['ci_lo'].to_numpy(), df['ci_hi'].to_numpy(), [mu_fe-1.96*se_fe, mu_fe+1.96*se_fe, mu_re-1.96*se_re, mu_re+1.96*se_re]]\n",
        "pad = 0.08 * (x_all.max() - x_all.min() + 1e-9)\n",
        "ax.set_xlim(x_all.min() - pad, x_all.max() + pad)\n",
        "\n",
        "title = f\"Toy meta-analysis (k={k}) | tau²={tau2:.4f}, I²={I2:.1f}%\"\n",
        "ax.set_title(title)\n",
        "ax.set_ylim(y_re - 1.0, k + 1.2)\n",
        "ax.grid(axis='x', color='0.9', lw=0.8)\n",
        "\n",
        "# Secondary axis for OR\n",
        "sec = ax.secondary_xaxis('top', functions=(np.exp, np.log))\n",
        "sec.set_xlabel('Odds Ratio (exp)')\n",
        "\n",
        "forest_path = OUT_DIR / 'forest_plot.png'\n",
        "fig.tight_layout()\n",
        "fig.savefig(forest_path, dpi=200, bbox_inches='tight')\n",
        "plt.close(fig)\n",
        "\n",
        "forest_path, summary_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Append run log\n",
        "run_log_path = OUT_DIR / 'run_log.txt'\n",
        "ts = datetime.now(timezone.utc).astimezone().isoformat(timespec='seconds')\n",
        "\n",
        "log_lines = [\n",
        "    f\"[{ts}] meta_analysis_demo run\",\n",
        "    f\"  csv: {csv_path}\",\n",
        "    f\"  summary: {summary_path}\",\n",
        "    f\"  forest_plot: {forest_path}\",\n",
        "    f\"  fixed: mu={mu_fe:.4f}, se={se_fe:.4f}, ci=[{mu_fe-1.96*se_fe:.4f}, {mu_fe+1.96*se_fe:.4f}]\",\n",
        "    f\"  random: mu={mu_re:.4f}, se={se_re:.4f}, ci=[{mu_re-1.96*se_re:.4f}, {mu_re+1.96*se_re:.4f}], tau2={tau2:.6f}\",\n",
        "    f\"  heterogeneity: Q={Q:.4f}, df={df_q}, I2={I2:.1f}%\",\n",
        "    \"\",\n",
        "]\n",
        "with run_log_path.open('a', encoding='utf-8') as f:\n",
        "    f.write(\"\\n\".join(log_lines))\n",
        "\n",
        "run_log_path"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
