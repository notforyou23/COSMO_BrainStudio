{
  "manifestVersion": "2.0.0-plan",
  "agentId": "agent_1766738871885_6jrar9j",
  "agentType": "code-creation",
  "goalId": "goal_135",
  "missionId": "strategic_goal_135_1766738871885",
  "spawnCycle": 152,
  "coordinatorReview": null,
  "spawnedBy": "strategic_spawner",
  "triggerSource": "strategic_goal",
  "spawningReason": "high",
  "createdAt": "2025-12-26T08:48:07.462Z",
  "completedAt": null,
  "canonical": false,
  "supersedes": [],
  "supersededBy": null,
  "deliverableType": "code",
  "files": [
    {
      "path": "README.md",
      "description": "Project overview with setup, dataset format, and end-to-end instructions to run the retrieve-then-verify baseline and evaluation outputs.",
      "category": "documentation",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "pyproject.toml",
      "description": "Python project configuration including dependencies, console scripts, and tool settings for a minimal reproducible baseline.",
      "category": "config",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/__init__.py",
      "description": "Package initializer exposing the main pipeline and evaluation entrypoints for the retrieve-then-verify baseline.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/types.py",
      "description": "Dataclasses and type definitions for atomic claims, evidence chunks, retrieval results, verification decisions, and evaluation records.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/claim_decompose.py",
      "description": "Rule-based claim decomposition that converts an input claim into atomic claims with fixed machine-readable fields (subject, predicate, scope, provenance requirements).",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/retrieval.py",
      "description": "Minimal retriever (BM25-like + optional TF-IDF fallback) over a local corpus with chunking, scoring, and top-k evidence selection.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/verify.py",
      "description": "Quote-attribution checks and support/contradict/insufficient decision logic with an abstain rule based on evidence quality and calibration thresholds.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/calibration.py",
      "description": "Calibration utilities (temperature scaling / isotonic option) and risk-tier thresholding to control false-accept rates under specified budgets.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/eval.py",
      "description": "Evaluation runner for a curated dataset computing accuracy, abstention, calibration metrics, and false-accept at multiple risk tiers with report export.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "src/rtv_baseline/cli.py",
      "description": "Command-line interface to build the corpus index, run the retrieve-then-verify pipeline on examples, and execute calibrated evaluation with saved artifacts.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "data/curated_eval.jsonl",
      "description": "Small curated evaluation set in JSONL with claims, expected labels, and optional gold evidence to test decomposition, retrieval, verification, and abstention.",
      "category": "support",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    },
    {
      "path": "tests/test_pipeline_smoke.py",
      "description": "Smoke tests ensuring decomposition, retrieval, verification, calibration, and evaluation run end-to-end on the curated set with deterministic outputs.",
      "category": "test",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T08:48:07.462Z"
    }
  ],
  "integrationStatus": "pending",
  "reviewNotes": null,
  "missionDescription": "Implement a minimal retrieve-then-verify baseline with: (a) claim decomposition, (b) retrieval, (c) quote-attribution checks, (d) support label + abstain rule; then evaluate on a small curated set with calibration + false-accept at risk tiers.",
  "missionSuccessCriteria": [
    "Complete strategic task identified by Meta-Coordinator or escalated by Strategic Tracker",
    "Curated insight (actionability 8-9/10): Directly operationalizes an evidence-first disposition for borderline-confidence QA by enforcing retrieve-then-verify with strict source/quote requirements and abstaining when support is weak. This is..."
  ],
  "projectName": "generated_script_1766738872100",
  "language": "python",
  "type": "script",
  "status": "in_progress",
  "requirements": [],
  "lastSavedAt": "2025-12-26T08:48:07.462Z"
}