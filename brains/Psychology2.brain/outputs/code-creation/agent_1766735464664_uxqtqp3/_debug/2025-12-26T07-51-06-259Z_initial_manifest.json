{
  "manifestVersion": "2.0.0-plan",
  "agentId": "agent_1766735464664_uxqtqp3",
  "agentType": "code-creation",
  "goalId": "goal_186",
  "missionId": "urgent_goal_186_1766735464664",
  "spawnCycle": 116,
  "coordinatorReview": null,
  "spawnedBy": "meta_coordinator_urgent",
  "triggerSource": "urgent_goal",
  "spawningReason": "high",
  "createdAt": "2025-12-26T07:51:16.604Z",
  "completedAt": null,
  "canonical": false,
  "supersedes": [],
  "supersededBy": null,
  "deliverableType": "code",
  "files": [
    {
      "path": "src/api_server.py",
      "description": "Implements the HTTP API server with end-to-end DOI resolution, normalization, and explicit provenance fields (landing_url, accessed_at, parsing_method, failure_reason_code) plus structured logging.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "src/doi_pipeline.py",
      "description": "Provides the core DOI processing pipeline (resolve redirects/paywalls, fetch/parse metadata, normalize fields, emit JSON records) with deterministic failure reason codes.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "src/provenance.py",
      "description": "Defines provenance and failure code schemas/enums and helpers to consistently populate accessed timestamps, landing URLs, parsing methods, and error categorization.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "src/exporters.py",
      "description": "Writes normalized outputs to JSONL/JSON and CSV with stable column order and embeds provenance fields while also saving per-run logs to disk.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "src/logging_setup.py",
      "description": "Sets up JSON structured logging with run_id correlation, request/response timing, and file handlers for saving logs under an artifacts directory.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "scripts/run_end_to_end.py",
      "description": "Runs api_server.py end-to-end against the curated DOI test set, captures responses, and saves normalized outputs (JSON + CSV + logs) with a reproducible run manifest.",
      "category": "support",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "data/doi_test_set.json",
      "description": "Curated DOI test set containing representative edge cases (redirects, paywalls, multiple editions, invalid/retired DOIs) with human-readable labels and expected behaviors.",
      "category": "config",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "tests/test_cli_end_to_end.py",
      "description": "End-to-end test that spins up the API server, executes the runner over the DOI test set, and asserts outputs include required provenance fields and valid failure codes.",
      "category": "test",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "docs/doi_test_set_and_provenance.md",
      "description": "Documents the curated DOI test set rationale, edge-case coverage, failure reason code taxonomy, and the exact output schemas for JSON/CSV/logs.",
      "category": "documentation",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    },
    {
      "path": "src/schemas.py",
      "description": "Defines the normalized citation record schema (pydantic/dataclasses) shared by the API, pipeline, and exporters to ensure consistent JSON/CSV field names and types.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:51:16.604Z"
    }
  ],
  "integrationStatus": "pending",
  "reviewNotes": null,
  "missionDescription": "Create a small curated DOI test set (covering edge cases like redirects/paywalls/multiple editions), run api_server.py end-to-end, and save normalized outputs (JSON + CSV + logs) with explicit provenance fields (landing URL, accessed timestamp, parsing method, failure reason codes).",
  "missionSuccessCriteria": [
    "Complete the urgent task identified by Meta-Coordinator",
    "Curated insight (actionability 8-9/10): Validates the primary-source/citation access MVP via real end-to-end execution (DOI list → retrieval → structured outputs), turning the tooling into an empirically testable component and producing art..."
  ],
  "projectName": "small curated DOI test set (covering edge cases like redirects/paywalls/multiple editions), run api_server.py end-to-end, and save normalized outputs (JSON + CSV + logs) with explicit provenance fields (landing URL, accessed timestamp, parsing method, failure reason codes).",
  "language": "python",
  "type": "api_server",
  "status": "in_progress",
  "requirements": [],
  "lastSavedAt": "2025-12-26T07:51:16.604Z"
}