{
  "manifestVersion": "2.0.0-plan",
  "agentId": "agent_1766732620182_hknpklb",
  "agentType": "code-creation",
  "goalId": "goal_147",
  "missionId": "urgent_goal_147_1766732620182",
  "spawnCycle": 88,
  "coordinatorReview": null,
  "spawnedBy": "meta_coordinator_urgent",
  "triggerSource": "urgent_goal",
  "spawningReason": "high",
  "createdAt": "2025-12-26T07:03:49.718Z",
  "completedAt": null,
  "canonical": false,
  "supersedes": [],
  "supersededBy": null,
  "deliverableType": "code",
  "files": [
    {
      "path": "src/uncertainty_signals.py",
      "description": "Implements per-claim uncertainty signals (e.g., self-consistency, token/logprob-based surrogates, heuristic detectors) and a unified interface to compute them for each claim.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "src/routing_policy.py",
      "description": "Defines routing decisions (auto-answer vs escalate vs abstain) based on uncertainty signals, configurable thresholds, and risk-tier policies.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "src/threshold_sweep.py",
      "description": "Runs threshold sweeps across risk tiers and aggregates metrics to estimate human-review cost versus error under different routing thresholds.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "src/evaluation.py",
      "description": "Computes evaluation metrics (error, coverage, escalation rate, abstention rate, expected cost) given ground-truth labels and routing outcomes.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "src/data_models.py",
      "description": "Defines dataclasses/typed schemas for claims, per-claim signals, routing outputs, and evaluation records to keep the pipeline consistent.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "src/io_utils.py",
      "description": "Handles reading/writing datasets and results (JSONL/CSV), including saving sweep curves and per-claim decision traces for analysis.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "src/main.py",
      "description": "CLI entrypoint that loads a labeled claim dataset, computes uncertainty signals, applies routing, performs threshold sweep, and writes summary outputs.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "configs/example.yaml",
      "description": "Example configuration specifying signal settings, routing thresholds per risk tier, and cost assumptions for human review and errors.",
      "category": "config",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    },
    {
      "path": "README.md",
      "description": "Documentation describing how to run the script, expected input schema, configuration options, and interpreting the cost-vs-error sweep outputs.",
      "category": "documentation",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.718Z"
    }
  ],
  "integrationStatus": "pending",
  "reviewNotes": null,
  "missionDescription": "Implement per-claim uncertainty signals and a routing policy (auto-answer vs. escalate vs. abstain), then run a threshold sweep to estimate human-review cost vs. error at each risk tier.",
  "missionSuccessCriteria": [
    "Complete the urgent task identified by Meta-Coordinator",
    "Curated insight (actionability 8-9/10): Provides an operational policy ('selective generation/abstention') that maps naturally to the planned risk tiers and expected dispositions (accept/abstain/defer), enabling measurable trade-offs among ..."
  ],
  "projectName": "generated_script_1766732620428",
  "language": "python",
  "type": "script",
  "status": "in_progress",
  "requirements": [],
  "lastSavedAt": "2025-12-26T07:03:49.718Z"
}