{
  "manifestVersion": "2.0.0-plan",
  "agentId": "agent_1766732620180_f1g6awd",
  "agentType": "code-creation",
  "goalId": "goal_145",
  "missionId": "urgent_goal_145_1766732620179",
  "spawnCycle": 88,
  "coordinatorReview": null,
  "spawnedBy": "meta_coordinator_urgent",
  "triggerSource": "urgent_goal",
  "spawningReason": "high",
  "createdAt": "2025-12-26T07:03:49.800Z",
  "completedAt": null,
  "canonical": false,
  "supersedes": [],
  "supersededBy": null,
  "deliverableType": "code",
  "files": [
    {
      "path": "pyproject.toml",
      "description": "Project configuration defining dependencies, entry points, and tooling for the retrieve-then-verify baseline and evaluation harness integration.",
      "category": "config",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/__init__.py",
      "description": "Package initializer for the borderline QA baseline pipeline and evaluation utilities.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/citations.py",
      "description": "Implements must-cite data structures and validators enforcing quote+URL/DOI+span mappings with deterministic checks and normalization.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/retriever.py",
      "description": "Baseline retriever module that fetches candidate sources (web and/or local corpus) and returns ranked passages with stable IDs and provenance metadata.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/verifier.py",
      "description": "Verifier module that checks model answers against retrieved passages and enforces explicit must-cite constraints including exact-quote and span alignment.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/pipeline.py",
      "description": "End-to-end retrieve-then-verify pipeline wiring retrieval, answer generation, and citation verification into a single callable interface for the harness.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/self_confidence_baseline.py",
      "description": "Implements a self-confidence prompting baseline producing selective predictions without explicit citation constraints for false-accept comparison.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/harness_adapter.py",
      "description": "Adapter layer that integrates the pipelines into the borderline QA evaluation harness output schema and logs decisions for FAR/coverage analysis.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "src/borderline_qa/eval_run.py",
      "description": "CLI entry point to run the harness with both baselines and compute comparative metrics including false-accept rates under selective prediction.",
      "category": "source",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "tests/test_must_cite_constraints.py",
      "description": "Unit tests covering must-cite validation rules for quote matching, URL/DOI presence, and span mapping edge cases.",
      "category": "test",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": "tests/test_pipeline_vs_self_confidence_far.py",
      "description": "Integration tests exercising the harness adapter to compare false-accept behavior between retrieve-then-verify and self-confidence baselines on fixtures.",
      "category": "test",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    },
    {
      "path": ".github/workflows/ci.yml",
      "description": "CI workflow running lint-free checks and pytest to satisfy the explicit CI/CD requirement for the implementation.",
      "category": "config",
      "stage": 1,
      "stageLabel": "Stage 1",
      "stageGoal": null,
      "mode": "create",
      "maxLines": 150,
      "maxChars": null,
      "status": "pending",
      "attempts": 0,
      "errors": [],
      "createdAt": "2025-12-26T07:03:49.800Z"
    }
  ],
  "integrationStatus": "pending",
  "reviewNotes": null,
  "missionDescription": "Implement a baseline retrieve-then-verify pipeline with explicit 'must-cite' constraints (quote+URL/DOI+span mapping) and wire it into the borderline QA evaluation harness to compare false-accept rates vs. self-confidence prompting.",
  "missionSuccessCriteria": [
    "Complete the urgent task identified by Meta-Coordinator",
    "Curated insight (actionability 8-9/10): Directly motivates an evidence-first (retrieve-then-verify) architecture with strict source/quote attribution requirements, enabling head-to-head benchmarking against self-confidence prompting and sup..."
  ],
  "projectName": "generated_script_1766732620395",
  "language": "python",
  "type": "script",
  "status": "in_progress",
  "requirements": [
    "include_ci_cd"
  ],
  "lastSavedAt": "2025-12-26T07:03:49.801Z"
}